{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Codegen Lab","text":"<p>This is the documentation for the Codegen Lab project.</p>"},{"location":"#overview","title":"Overview","text":"<p>Codegen Lab is a project focused on code generation and AI-assisted development tools. This documentation will guide you through the installation, configuration, and usage of Codegen Lab.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Feature 1: Brief description</li> <li>Feature 2: Brief description</li> <li>Feature 3: Brief description</li> <li>Cursor Rules: Custom workflow automations for iterative development in existing codebases</li> <li>UV Workspace: Efficient management of multiple packages within a single repository</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone the repository\ngit clone https://github.com/bossjones/codegen-lab.git\ncd codegen-lab\n\n# Install dependencies\nuv sync --frozen\n</code></pre>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Getting Started: Basic introduction and setup</li> <li>User Guide: Detailed usage instructions</li> <li>Development Tools: Tools and workflows for effective development</li> <li>Cursor Rules: Workflow automations for iterative development</li> <li>UV Workspace: Package management within a monorepo structure</li> <li>API Reference: Technical reference for APIs</li> <li>Contributing: Guidelines for contributors</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>This page provides detailed documentation for the Codegen Lab API.</p>"},{"location":"api-reference/#core-api","title":"Core API","text":""},{"location":"api-reference/#codegen_labgenerate","title":"<code>codegen_lab.generate</code>","text":"<p>Main function for generating code based on a prompt.</p> <pre><code>from codegen_lab import generate\n\ncode = generate(\n    prompt=\"Create a Python function to calculate the Fibonacci sequence\",\n    model=\"gpt-4\",\n    temperature=0.7,\n    max_tokens=1024\n)\n\nprint(code)\n</code></pre>"},{"location":"api-reference/#parameters","title":"Parameters","text":"Parameter Type Description Default <code>prompt</code> <code>str</code> The prompt to generate code from Required <code>model</code> <code>str</code> Model to use \"gpt-3.5-turbo\" <code>temperature</code> <code>float</code> Temperature parameter (0.0-1.0) 0.7 <code>max_tokens</code> <code>int</code> Maximum tokens to generate 1024 <code>top_p</code> <code>float</code> Top-p sampling parameter 0.9 <code>stop</code> <code>list[str]</code> Sequences where generation should stop None"},{"location":"api-reference/#returns","title":"Returns","text":"<p><code>str</code>: The generated code.</p>"},{"location":"api-reference/#exceptions","title":"Exceptions","text":"<ul> <li><code>ValueError</code>: If prompt is empty or parameters are invalid</li> <li><code>ConnectionError</code>: If there's an issue connecting to the model API</li> <li><code>AuthenticationError</code>: If API credentials are invalid</li> </ul>"},{"location":"api-reference/#codegen_labenhance","title":"<code>codegen_lab.enhance</code>","text":"<p>Enhance existing code with improvements, documentation, or tests.</p> <pre><code>from codegen_lab import enhance\n\noriginal_code = \"\"\"\ndef fibonacci(n):\n    if n &lt;= 0:\n        return []\n    if n == 1:\n        return [0]\n    sequence = [0, 1]\n    for i in range(2, n):\n        sequence.append(sequence[i-1] + sequence[i-2])\n    return sequence\n\"\"\"\n\nenhanced_code = enhance(\n    code=original_code,\n    enhancement_type=\"documentation\",\n    language=\"python\"\n)\n\nprint(enhanced_code)\n</code></pre>"},{"location":"api-reference/#parameters_1","title":"Parameters","text":"Parameter Type Description Default <code>code</code> <code>str</code> The code to enhance Required <code>enhancement_type</code> <code>str</code> Type of enhancement (\"documentation\", \"performance\", \"tests\", \"all\") \"all\" <code>language</code> <code>str</code> Programming language of the code \"python\" <code>model</code> <code>str</code> Model to use \"gpt-3.5-turbo\" <code>temperature</code> <code>float</code> Temperature parameter (0.0-1.0) 0.7"},{"location":"api-reference/#returns_1","title":"Returns","text":"<p><code>str</code>: The enhanced code.</p>"},{"location":"api-reference/#utility-functions","title":"Utility Functions","text":""},{"location":"api-reference/#codegen_labutilsvalidate_code","title":"<code>codegen_lab.utils.validate_code</code>","text":"<p>Validate generated code for syntax errors and other issues.</p> <pre><code>from codegen_lab.utils import validate_code\n\ncode = \"\"\"\ndef hello_world():\n    print(\"Hello, world!\")\n\"\"\"\n\nis_valid, issues = validate_code(code, language=\"python\")\n\nif is_valid:\n    print(\"Code is valid!\")\nelse:\n    print(\"Issues found:\", issues)\n</code></pre>"},{"location":"api-reference/#parameters_2","title":"Parameters","text":"Parameter Type Description Default <code>code</code> <code>str</code> The code to validate Required <code>language</code> <code>str</code> Programming language of the code \"python\" <code>strict</code> <code>bool</code> Enable strict validation False"},{"location":"api-reference/#returns_2","title":"Returns","text":"<ul> <li><code>bool</code>: Whether the code is valid</li> <li><code>list[str]</code>: List of issues found, empty if code is valid</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Bboxes: Add autocrop functionality for tweet and object detection Enhance image processing capabilities by introducing:</li> <li>Bboxes: Add comprehensive image processing with directory support Enhance the bounding box script with robust directory and file processing capabilities:</li> <li>Bboxes: Add Gemini model temperature control Enhance image processing with configurable Gemini model temperature:</li> <li>Bboxes: Add image resizing with primary color background Enhance image processing capabilities by introducing:</li> <li>Bboxes: Add robust retry mechanism for Gemini API calls Enhance Gemini API interaction reliability with:</li> <li>Bboxes: Enhance AI-powered image bounding box detection Improve tweet and object detection with advanced coordinate handling:</li> <li>Cheatsheets: Add Taskfile cheatsheet and repomix cheatsheet</li> <li>Cursor: Add cheatsheet creation best practices documentation - Comprehensive guidelines for creating well-structured command cheatsheets</li> <li>Cursor: Add MCP server configuration for memory file path - Configure the Cursor MCP server with a memory file path</li> <li>Cursor: Add MCP server development guidelines and best practices - Comprehensive documentation for developing Model Context Protocol (MCP) servers in Python</li> <li>Dependencies: Add Google Generative AI and supporting libraries Update project dependencies to include:</li> <li>Dependencies: Add tenacity library for retry and resilience Add tenacity library to project dependencies to support robust retry mechanisms and improve error handling for network and API interactions. This addition provides advanced retry strategies and can enhance the reliability of external service calls.</li> <li>Makefile: Update Taskfile copy destination path - Modify the <code>copy-global-taskfile</code> target to use <code>~/Taskfile.yml</code> instead of <code>~/.taskfile.yml</code></li> <li>Taskfile: Add empty line in Taskfile.yml - Minor whitespace adjustment to improve readability</li> <li>VSCode: Add VSCode settings and Taskfile schema integration</li> <li>Basic API functionality</li> <li>Basic documentation</li> <li>Command-line interface</li> <li>Core code generation functionality</li> <li>Documentation structure</li> <li>Initial project setup</li> <li>Initial release</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Cursor: Add output.txt context extraction guidelines - Enhanced documentation for working with output.txt files</li> <li>Fastmcp: Add comprehensive FastMCP server development examples - Expanded documentation with detailed usage examples</li> <li>Fastmcp: Add comprehensive FastMCP server testing guidelines Enhance FastMCP documentation with detailed testing guidelines, including:</li> <li>Fastmcp: Enhance server development guidelines with examples - Detailed server type selection and implementation guidelines</li> <li>Fastmcp: Expand documentation with advanced MCP server examples - Comprehensive usage examples and demonstrations</li> <li>Taskfile: Update Taskfile schema and improve organization</li> <li>N/A</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>N/A</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Bboxes: Update PIL image resizing method to use Resampling enum Replace deprecated LANCZOS constant with the recommended Resampling.LANCZOS enum in image resizing to ensure compatibility with newer Pillow versions. This change maintains the high-quality resizing behavior while adhering to the latest PIL API guidelines.</li> <li>N/A</li> </ul>"},{"location":"changelog/#020-2025-03-02","title":"0.2.0 - 2025-03-02","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Cheatsheets: Add Taskfile cheatsheet and repomix cheatsheet</li> <li>Cursor: Add cheatsheet creation best practices documentation - Comprehensive guidelines for creating well-structured command cheatsheets</li> <li>Cursor: Add MCP server configuration for memory file path - Configure the Cursor MCP server with a memory file path</li> <li>Cursor: Add MCP server development guidelines and best practices - Comprehensive documentation for developing Model Context Protocol (MCP) servers in Python</li> <li>Makefile: Update Taskfile copy destination path - Modify the <code>copy-global-taskfile</code> target to use <code>~/Taskfile.yml</code> instead of <code>~/.taskfile.yml</code></li> <li>Taskfile: Add empty line in Taskfile.yml - Minor whitespace adjustment to improve readability</li> <li>VSCode: Add VSCode settings and Taskfile schema integration</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Cursor: Add output.txt context extraction guidelines - Enhanced documentation for working with output.txt files</li> <li>Fastmcp: Add comprehensive FastMCP server development examples - Expanded documentation with detailed usage examples</li> <li>Fastmcp: Enhance server development guidelines with examples - Detailed server type selection and implementation guidelines</li> <li>Fastmcp: Expand documentation with advanced MCP server examples - Comprehensive usage examples and demonstrations</li> <li>Taskfile: Update Taskfile schema and improve organization</li> </ul>"},{"location":"changelog/#010-2025-02-15","title":"0.1.0 - 2025-02-15","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Initial release</li> <li>Core code generation functionality</li> <li>Basic API functionality</li> <li>Command-line interface</li> <li>Basic documentation</li> <li>Documentation structure</li> <li>Initial project setup</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>N/A</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>N/A</li> </ul>"},{"location":"changelog/#removed_1","title":"Removed","text":"<ul> <li>N/A</li> </ul>"},{"location":"changelog/#how-to-update-the-changelog","title":"How to Update the Changelog","text":"<ol> <li>Always add new entries at the top under the <code>[Unreleased]</code> section</li> <li>Group changes by type: Added, Changed, Deprecated, Removed, Fixed, Security</li> <li>When releasing a new version, rename the <code>[Unreleased]</code> section to the new version number and date</li> <li>Create a new <code>[Unreleased]</code> section at the top</li> <li>Use link references at the bottom of the file for version comparisons</li> </ol>"},{"location":"contributing/","title":"Contributing to Codegen Lab","text":"<p>Thank you for your interest in contributing to Codegen Lab! This document provides guidelines and instructions for contributors.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please read and follow our Code of Conduct before contributing.</p>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":"<p>There are many ways to contribute to Codegen Lab:</p> <ol> <li>Reporting Bugs: Report bugs by opening an issue on the GitHub repository.</li> <li>Suggesting Enhancements: Suggest new features or improvements by opening an issue.</li> <li>Pull Requests: Submit pull requests with bug fixes, improvements, or new features.</li> <li>Documentation: Help improve documentation or fix typos.</li> <li>Answering Questions: Help answer questions in issues or discussions.</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Clone your fork to your local machine:</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/codegen-lab.git\ncd codegen-lab\n</code></pre> <ol> <li>Create a new branch for your changes:</li> </ol> <pre><code>git checkout -b feature/your-feature-name\n</code></pre> <ol> <li>Set up the development environment:</li> </ol> <pre><code>uv venv --python 3.12.0\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv sync --frozen --dev\n</code></pre> <ol> <li>Make your changes and commit them with a clear, descriptive commit message.</li> </ol>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Ensure your code follows the project's style guidelines.</li> <li>Update documentation if necessary.</li> <li>Add tests for your changes.</li> <li>Make sure all tests pass:</li> </ol> <pre><code>uv run pytest tests/\n</code></pre> <ol> <li>Push your changes to your fork:</li> </ol> <pre><code>git push origin feature/your-feature-name\n</code></pre> <ol> <li>Submit a pull request to the main repository.</li> <li>The maintainers will review your pull request and provide feedback.</li> </ol>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow PEP 8 for Python code.</li> <li>Add type hints to functions and methods.</li> <li>Write clear, descriptive docstrings following PEP 257.</li> <li>Use meaningful variable and function names.</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write tests for all new features and bug fixes.</li> <li>Use pytest for testing.</li> <li>Aim for high test coverage.</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Update documentation for any changes to the API or behavior.</li> <li>Use clear, concise language.</li> <li>Provide examples for API usage.</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing to Codegen Lab, you agree that your contributions will be licensed under the project's license.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get started with Codegen Lab.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.10 or higher</li> <li>UV package manager</li> <li>Git</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/bossjones/codegen-lab.git\ncd codegen-lab\n</code></pre> <ol> <li>Set up a virtual environment:</li> </ol> <pre><code>uv venv --python 3.12.0\n</code></pre> <ol> <li>Activate the virtual environment:</li> </ol> <pre><code># On Unix or MacOS\nsource .venv/bin/activate\n\n# On Windows\n.venv\\Scripts\\activate\n</code></pre> <ol> <li>Install dependencies:</li> </ol> <pre><code>uv sync --frozen\n</code></pre>"},{"location":"getting-started/#verification","title":"Verification","text":"<p>Verify the installation by running:</p> <pre><code>python -m codegen_lab --version\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have Codegen Lab installed, you can:</p> <ol> <li>Explore the User Guide for detailed usage instructions</li> <li>Check the API Reference for technical details</li> <li>Start using Codegen Lab in your projects</li> </ol>"},{"location":"prompt_library_mcp_server/","title":"Cursor Rules Prompt Library","text":"<p>This FastMCP server exposes cursor rules as resources and provides a prompt endpoint for creating custom cursor rules based on user input.</p>"},{"location":"prompt_library_mcp_server/#features","title":"Features","text":"<ul> <li>Resource Endpoints:</li> <li><code>cursor-rules://list</code> - List all available cursor rules</li> <li><code>cursor-rule://{name}</code> - Get a cursor rule by name (parsed structure)</li> <li> <p><code>cursor-rule-raw://{name}</code> - Get the raw content of a cursor rule by name</p> </li> <li> <p>Prompt Endpoints:</p> </li> <li><code>repo-analysis</code> - Analyze a repository to gather information for cursor rule creation</li> <li> <p><code>generate-cursor-rule</code> - Generate a custom cursor rule based on repository information</p> </li> <li> <p>Tool Endpoints:</p> </li> <li><code>save_cursor_rule</code> - Save a cursor rule to the cursor rules directory</li> </ul>"},{"location":"prompt_library_mcp_server/#usage","title":"Usage","text":""},{"location":"prompt_library_mcp_server/#running-the-server","title":"Running the Server","text":"<pre><code>python -m examples.fastmcp.prompt_library\n</code></pre>"},{"location":"prompt_library_mcp_server/#listing-cursor-rules","title":"Listing Cursor Rules","text":"<pre><code>from mcp.client import Client\nfrom pydantic import AnyUrl\n\nasync with Client() as client:\n    result = await client.read_resource(AnyUrl(\"cursor-rules://list\"))\n    rules = json.loads(result.contents[0].text)\n    for rule in rules:\n        print(f\"{rule['name']}: {rule['description']}\")\n</code></pre>"},{"location":"prompt_library_mcp_server/#getting-a-cursor-rule","title":"Getting a Cursor Rule","text":"<pre><code>from mcp.client import Client\nfrom pydantic import AnyUrl\n\nasync with Client() as client:\n    result = await client.read_resource(AnyUrl(\"cursor-rule://anthropic-chain-of-thought\"))\n    rule = json.loads(result.contents[0].text)\n    print(f\"Title: {rule['title']}\")\n    print(f\"Description: {rule['description']}\")\n    print(f\"Rule: {rule['rule']['name']}\")\n</code></pre>"},{"location":"prompt_library_mcp_server/#analyzing-a-repository","title":"Analyzing a Repository","text":"<pre><code>from mcp.client import Client\n\nasync with Client() as client:\n    result = await client.get_prompt(\"repo-analysis\", {\n        \"repo_description\": \"A Python web application using FastAPI and SQLAlchemy\",\n        \"main_languages\": \"Python\",\n        \"file_patterns\": \"*.py\",\n        \"key_features\": \"API, Database, Authentication\"\n    })\n\n    # Send the prompt to an LLM for completion\n    completion = await client.create_message(result.messages)\n    print(completion.content[0].text)\n</code></pre>"},{"location":"prompt_library_mcp_server/#generating-a-custom-cursor-rule","title":"Generating a Custom Cursor Rule","text":"<pre><code>from mcp.client import Client\nimport json\n\nasync with Client() as client:\n    result = await client.get_prompt(\"generate-cursor-rule\", {\n        \"rule_name\": \"fastapi-best-practices\",\n        \"description\": \"Best practices for FastAPI applications\",\n        \"file_patterns\": \"*.py\",\n        \"content_patterns\": \"fastapi, APIRouter, Depends\",\n        \"action_message\": \"When using FastAPI, follow these best practices:\\n\\n1. Use dependency injection\\n2. Validate input with Pydantic models\\n3. Use proper status codes\\n4. Document your endpoints\",\n        \"examples\": json.dumps([\n            {\n                \"input\": \"# Bad: No input validation\\n@app.post('/users')\\ndef create_user(user_data: dict):\\n    return db.create_user(user_data)\\n\\n# Good: Proper input validation\\n@app.post('/users', status_code=201)\\ndef create_user(user: UserCreate):\\n    return db.create_user(user.dict())\",\n                \"output\": \"Using Pydantic models for input validation\"\n            }\n        ]),\n        \"tags\": \"fastapi, best-practices, web-development\",\n        \"priority\": \"high\"\n    })\n\n    # Send the prompt to an LLM for completion\n    completion = await client.create_message(result.messages)\n    print(completion.content[0].text)\n\n    # Save the generated rule\n    rule_content = completion.content[0].text.split(\"```markdown\\n\")[1].split(\"```\")[0]\n    result = await client.call_tool(\"save_cursor_rule\", {\n        \"rule_name\": \"fastapi-best-practices\",\n        \"rule_content\": rule_content\n    })\n    print(result.content[0].text)\n</code></pre>"},{"location":"prompt_library_mcp_server/#development","title":"Development","text":""},{"location":"prompt_library_mcp_server/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/unittests/test_prompt_library.py -v\n</code></pre>"},{"location":"prompt_library_mcp_server/#adding-new-features","title":"Adding New Features","text":"<ul> <li>To add a new resource endpoint, use the <code>@mcp.resource()</code> decorator</li> <li>To add a new prompt endpoint, use the <code>@mcp.prompt()</code> decorator</li> <li>To add a new tool endpoint, use the <code>@mcp.tool()</code> decorator</li> </ul>"},{"location":"prompt_library_mcp_server/#project-structure","title":"Project Structure","text":"<ul> <li><code>examples/fastmcp/prompt_library.py</code> - Main FastMCP server implementation</li> <li><code>tests/unittests/test_prompt_library.py</code> - Tests for the FastMCP server</li> <li><code>hack/drafts/cursor_rules/</code> - Directory containing cursor rule files</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page provides solutions to common issues you might encounter when using Codegen Lab.</p>"},{"location":"troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/#python-version-compatibility","title":"Python Version Compatibility","text":"<p>Issue: Error indicating an incompatible Python version.</p> <p>Solution: Codegen Lab requires Python 3.10 or higher. Upgrade your Python installation or use a tool like pyenv to manage multiple Python versions.</p> <pre><code># Install pyenv (macOS)\nbrew install pyenv\n\n# Install Python 3.12 with pyenv\npyenv install 3.12.0\n\n# Set Python 3.12 as the local version for this project\npyenv local 3.12.0\n</code></pre>"},{"location":"troubleshooting/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Issue: Dependency resolution failures or conflicts during installation.</p> <p>Solution: Try reinstalling with the <code>--reinstall</code> flag or in a fresh virtual environment.</p> <pre><code># Using UV (recommended)\nuv sync --frozen --reinstall\n\n# Alternative: Create a fresh environment\nrm -rf .venv\nuv venv --python 3.12.0\nsource .venv/bin/activate\nuv sync --frozen\n</code></pre>"},{"location":"troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"troubleshooting/#import-errors","title":"Import Errors","text":"<p>Issue: <code>ModuleNotFoundError</code> or similar import errors when running Codegen Lab.</p> <p>Solution: Ensure you've activated the virtual environment and installed all dependencies.</p> <pre><code># Activate virtual environment\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Verify installation\nuv pip list\n</code></pre>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":"<p>Issue: Code generation is slow or unstable.</p> <p>Solution:</p> <ol> <li>Check your internet connection if using cloud-based models</li> <li>Verify system resources (RAM, CPU) are sufficient</li> <li>Try reducing model complexity or batch size</li> <li>Update to the latest version of Codegen Lab</li> </ol> <pre><code># Update to latest version\nuv add --upgrade codegen-lab\n</code></pre>"},{"location":"troubleshooting/#model-specific-issues","title":"Model-Specific Issues","text":""},{"location":"troubleshooting/#api-rate-limits","title":"API Rate Limits","text":"<p>Issue: Encountering rate limits when using external API-based models.</p> <p>Solution: Implement exponential backoff retry logic or upgrade your API subscription tier.</p>"},{"location":"troubleshooting/#model-output-quality","title":"Model Output Quality","text":"<p>Issue: Poor quality code generation results.</p> <p>Solution:</p> <ol> <li>Improve your prompts with more context and examples</li> <li>Try a different model or adjust temperature settings</li> <li>Fine-tune the model on your specific use case (if applicable)</li> </ol>"},{"location":"troubleshooting/#environment-and-configuration-issues","title":"Environment and Configuration Issues","text":""},{"location":"troubleshooting/#configuration-file-not-found","title":"Configuration File Not Found","text":"<p>Issue: Codegen Lab can't find your configuration file.</p> <p>Solution: Ensure your configuration file is in the correct location or explicitly specify the path.</p> <pre><code>python -m codegen_lab --config path/to/config.yaml\n</code></pre>"},{"location":"troubleshooting/#environment-variables-not-applied","title":"Environment Variables Not Applied","text":"<p>Issue: Environment variable configurations aren't being applied.</p> <p>Solution: Verify environment variables are correctly set and take precedence over config files.</p> <pre><code># Set environment variables\nexport CODEGEN_MODEL_NAME=\"gpt-4\"\nexport CODEGEN_DEBUG=true\n\n# Verify environment variables\necho $CODEGEN_MODEL_NAME\n</code></pre>"},{"location":"troubleshooting/#getting-further-help","title":"Getting Further Help","text":"<p>If you encounter issues not covered in this guide:</p> <ol> <li>Check the GitHub Issues for similar problems and solutions</li> <li>Open a new issue with detailed information about your problem</li> <li>Join the community discussion in Discussions</li> </ol>"},{"location":"mcp-servers/prompt_library_mcp/","title":"Prompt library mcp","text":"<p>Ok, here's a breakdown of the <code>plan_and_execute_prompt_library_workflow</code> tool's actions, step by step, based on the provided code:</p> <ol> <li> <p>Initialization:</p> <ul> <li>The tool receives repository information (<code>repo_description</code>, <code>main_languages</code>, <code>file_patterns</code>, <code>key_features</code>), the current <code>phase</code> of the workflow (defaulting to 1), and the <code>workflow_state</code>.</li> <li>If <code>workflow_state</code> is not provided or is invalid, it initializes a new workflow state. This state stores repository information, recommended/created/deployed rules, and workspace preparation status. It also immediately calls <code>prep_workspace()</code> and stores the result.</li> </ul> </li> <li> <p>Phase Execution (Based on the <code>phase</code> input):</p> <ul> <li>The tool uses a conditional structure (<code>if/elif/else</code>) to determine which phase of the workflow to execute.  Each <code>execute_phase_X</code> function encapsulates the logic for a specific phase.</li> </ul> </li> <li> <p><code>execute_phase_1</code> (Repository Analysis):</p> <ul> <li>Workspace Check:  Verifies if the workspace is prepared (<code>workflow_state.get(\"workspace_prepared\")</code>). If not, it calls <code>prep_workspace()</code> to set up directories and updates the workflow state.</li> <li>Repo Analysis Prompt: Calls <code>repo_analysis_prompt</code> with repository information to get an analysis and rule suggestions.</li> <li>Results Processing: Parses the analysis results from <code>repo_analysis_prompt</code>'s output into a structured format, extracting repository type, common patterns, and recommended rules.</li> <li>State Update: Updates the <code>workflow_state</code> with the analysis results and marks <code>phase_1_complete</code> as <code>True</code>.</li> </ul> </li> <li> <p><code>execute_phase_2</code> (Rule Identification):</p> <ul> <li>Prerequisites Check: Checks if Phase 1 is complete.</li> <li>Repository Summary Creation: Creates a summary string from repository information to be used by the <code>recommend_cursor_rules</code> function.</li> <li>Rule Recommendation: Calls <code>recommend_cursor_rules</code> with the repository summary to get a list of recommended cursor rules.</li> <li>Rule Processing: Categorizes, prioritizes, and filters the recommended rules. It also attempts to identify dependencies between the rules.</li> <li>State Update: Updates the <code>workflow_state</code> with the recommended, categorized, and selected rules. Marks <code>phase_2_complete</code> as <code>True</code>.</li> </ul> </li> <li> <p><code>execute_phase_3</code> (Workspace Preparation):</p> <ul> <li>Prerequisites Check: Checks if Phase 2 is complete.</li> <li>Rule Name Processing: Extracts rule names from the selected rules, makes them filename-safe, and ensures uniqueness.</li> <li>Tool Execution:<ul> <li>Calls <code>ensure_makefile_task()</code> to ensure the Makefile has the <code>update-cursor-rules</code> task.</li> <li>Calls <code>update_dockerignore()</code> to exclude the cursor rules drafts directory from Docker builds.</li> <li>Calls <code>create_cursor_rule_files()</code> to create empty <code>.mdc.md</code> files for each rule in the <code>hack/drafts/cursor_rules</code> directory.</li> </ul> </li> <li>State Update:  Updates the <code>workflow_state</code> with the rule file names and marks <code>phase_3_complete</code> as <code>True</code>.</li> </ul> </li> <li> <p><code>execute_phase_4</code> (Rule Creation):</p> <ul> <li>Prerequisites Check: Checks if Phase 3 is complete.</li> <li>Rule Processing: Iterates through the rule file names and:<ul> <li>Extracts rule metadata (description, file patterns, content patterns, etc.) from <code>rule_file_mapping</code>.</li> <li>Calls <code>generate_cursor_rule()</code> to generate the content of the cursor rule in Markdown format.</li> <li>Calls <code>save_cursor_rule()</code> to save the generated content to a <code>.mdc.md</code> file in the <code>hack/drafts/cursor_rules</code> directory.</li> </ul> </li> <li>State Update: Updates the <code>workflow_state</code> with the created rules and any errors that occurred during rule creation. Marks <code>phase_4_complete</code> as <code>True</code> if any rules were successfully created.</li> </ul> </li> <li> <p><code>execute_phase_5</code> (Deployment and Testing):</p> <ul> <li>Prerequisites Check: Checks if Phase 4 is complete.</li> <li>Deployment: Calls <code>run_update_cursor_rules()</code> to execute the <code>update-cursor-rules</code> task in the Makefile, which copies the cursor rule files to the <code>.cursor/rules</code> directory.</li> <li>State Update: Updates the <code>workflow_state</code> with the deployed rules and marks <code>phase_5_complete</code> as <code>True</code>.</li> <li>Testing Instructions: Provides instructions for testing the deployed cursor rules.</li> </ul> </li> <li> <p>Return Value:</p> <ul> <li>Each <code>execute_phase_X</code> function returns a dictionary containing the status of the phase, a message, a checklist of completed tasks, relevant data (created rules, errors, etc.), the updated <code>workflow_state</code>, the <code>next_phase</code> to execute, and any <code>next_steps</code> for the user. The <code>plan_and_execute_prompt_library_workflow</code> tool returns this dictionary to the caller.</li> </ul> </li> </ol>"},{"location":"mcp-servers/prompt_library_mcp/#tool-calls","title":"Tool calls","text":""},{"location":"mcp-servers/prompt_library_mcp/#get_static_cursor_rules","title":"get_static_cursor_rules","text":"<p>Request:</p> <pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"get_static_cursor_rules\",\"arguments\":{\"rule_names\":[\"tree\",\"repomix\"]},\"_meta\":{\"progressToken\":0}}}\n</code></pre> <p>Response:</p> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"rules\\\": [{\\\"rule_name\\\": \\\"tree.mdc.md\\\", \\\"content\\\": \\\"---\\\\ndescription: Display repository structure\\\\nglobs: *\\\\nalwaysApply: false\\\\n---\\\\nWhen the user asks about the project layout, structure, or organization, run the command `tree -L 7 -I \\\\\\\"*.pyc|__pycache__|.git|.pytest_cache|.ruff_cache|.mypy_cache|.coverage|htmlcov|.venv|.env|*.egg-info|build|dist|node_modules|.DS_Store|images\\\\\\\"` to help understand and visualize the repository structure.\\\\n\\\"}, {\\\"rule_name\\\": \\\"repomix.mdc.md\\\", \\\"content\\\": \\\"---\\\\ndescription: Repomix tool\\\\nglobs: *\\\\nalwaysApply: false\\\\n---\\\\n# Repomix Project Layout\\\\n\\\\nRules for understanding and navigating the repomix project structure.\\\\n\\\\n&lt;rule&gt;\\\\nname: project_layout_guide\\\\ndescription: Guide to the repomix project structure and organization\\\\nfilters:\\\\n  # Match any file in the project\\\\n  - type: file_extension\\\\n    pattern: \\\\\\\".*\\\\\\\"\\\\n  # Match project initialization events\\\\n  - type: event\\\\n    pattern: \\\\\\\"file_create\\\\\\\"\\\\n\\\\nactions:\\\\n  - type: suggest\\\\n    message: |\\\\n      # Repomix Project Structure\\\\n\\\\n      This repository implements a tool for code repository summarization and packaging for LLM consumption.\\\\n\\\\n      ## Core Features\\\\n\\\\n      - **Repository Summarization:** Extracts and summarizes code repositories\\\\n      - **Code Packaging:** Prepares code for LLM consumption\\\\n      - **Security Checks:** Validates file safety and filters untrusted files\\\\n      - **Multiple Output Formats:** Supports markdown, plain text, and XML output styles\\\\n      - **CLI Interface:** Command-line interface for easy usage\\\\n      - **Web Interface:** Browser-based interface for repository processing\\\\n\\\\n      ## Directory Structure\\\\n\\\\n      ```\\\\n      .\\\\n      \\\\u251c\\\\u2500\\\\u2500 .cursor/                     # Active cursor rules directory\\\\n      \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 rules/                   # Production cursor rules\\\\n      \\\\u251c\\\\u2500\\\\u2500 bin/                         # Binary executables\\\\n      \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 repomix.cjs              # Main executable\\\\n      \\\\u251c\\\\u2500\\\\u2500 src/                         # Source code\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 cli/                     # Command-line interface\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 actions/             # CLI action implementations\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 cliPrint.ts          # CLI output utilities\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 cliRun.ts            # CLI execution logic\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 cliSpinner.ts        # CLI progress indicators\\\\n      \\\\u2502   \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 types.ts             # CLI type definitions\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 config/                  # Configuration handling\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 configLoad.ts        # Config loading utilities\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 configSchema.ts      # Config validation schema\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 defaultIgnore.ts     # Default ignore patterns\\\\n      \\\\u2502   \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 globalDirectory.ts   # Global directory management\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 core/                    # Core functionality\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 file/                # File operations\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 metrics/             # Metrics calculation\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 output/              # Output generation\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 packager/            # Output packaging\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 security/            # Security validation\\\\n      \\\\u2502   \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 tokenCount/          # Token counting utilities\\\\n      \\\\u2502   \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 treeSitter/          # Code parsing with tree-sitter\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 index.ts                 # Main entry point\\\\n      \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 shared/                  # Shared utilities\\\\n      \\\\u2502       \\\\u251c\\\\u2500\\\\u2500 constants.ts         # Shared constants\\\\n      \\\\u2502       \\\\u251c\\\\u2500\\\\u2500 errorHandle.ts       # Error handling\\\\n      \\\\u2502       \\\\u251c\\\\u2500\\\\u2500 logger.ts            # Logging utilities\\\\n      \\\\u2502       \\\\u251c\\\\u2500\\\\u2500 processConcurrency.ts # Concurrency management\\\\n      \\\\u2502       \\\\u2514\\\\u2500\\\\u2500 types.ts             # Shared type definitions\\\\n      \\\\u251c\\\\u2500\\\\u2500 tests/                       # Test suites\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 cli/                     # CLI tests\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 config/                  # Configuration tests\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 core/                    # Core functionality tests\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 integration-tests/       # Integration tests\\\\n      \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 shared/                  # Shared utility tests\\\\n      \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 testing/                 # Test utilities\\\\n      \\\\u2514\\\\u2500\\\\u2500 website/                     # Web interface\\\\n          \\\\u251c\\\\u2500\\\\u2500 client/                  # Frontend application\\\\n          \\\\u2502   \\\\u251c\\\\u2500\\\\u2500 components/          # Vue components\\\\n          \\\\u2502   \\\\u2514\\\\u2500\\\\u2500 src/                 # Frontend source code\\\\n          \\\\u2514\\\\u2500\\\\u2500 server/                  # Backend server\\\\n              \\\\u2514\\\\u2500\\\\u2500 src/                 # Server source code\\\\n      ```\\\\n\\\\n      ## Primary Components\\\\n\\\\n      ### Source Code (`src/`)\\\\n      Core TypeScript application code organized into modules:\\\\n      - `cli/`: Command-line interface implementation\\\\n      - `config/`: Configuration management\\\\n      - `core/`: Core functionality including file processing, security, and output generation\\\\n      - `shared/`: Shared utilities and types\\\\n\\\\n      ### Tests (`tests/`)\\\\n      Comprehensive test suite including unit tests and integration tests for all components.\\\\n\\\\n      ### Website (`website/`)\\\\n      Web interface for the application with client and server components:\\\\n      - `client/`: Vue-based frontend application\\\\n      - `server/`: Backend API server\\\\n\\\\n      ### Binary (`bin/`)\\\\n      Executable files for running the application from the command line.\\\\n\\\\n      ## Development Workflow\\\\n\\\\n      ### Feature Development\\\\n      1. **Understand Requirements** - Review existing code and documentation\\\\n      2. **Implement Changes** - Add or modify code with appropriate tests\\\\n      3. **Test Thoroughly** - Run tests to ensure functionality\\\\n      4. **Document Changes** - Update documentation as needed\\\\n\\\\n      ### Testing\\\\n      - Run unit tests: `npm test`\\\\n      - Run specific tests: `npm test -- &lt;test-pattern&gt;`\\\\n      - Run integration tests: `npm run test:integration`\\\\n\\\\n      ### Building\\\\n      - Build the application: `npm run build`\\\\n      - Build the website: `cd website &amp;&amp; npm run build`\\\\n\\\\nexamples:\\\\n  - input: |\\\\n      # I'm new to the project, where should I put my code for a new CLI command?\\\\n    output: |\\\\n      For a new CLI command, you should:\\\\n\\\\n      1. Create a new action file in `src/cli/actions/` (e.g., `myNewAction.ts`)\\\\n      2. Implement the action following the pattern of existing actions\\\\n      3. Add appropriate tests in `tests/cli/actions/`\\\\n      4. Update the CLI command registration in the main CLI runner\\\\n\\\\n      Look at existing action files like `defaultAction.ts` or `initAction.ts` for examples of the structure.\\\\n\\\\n  - input: |\\\\n      # How is the code parsing functionality organized?\\\\n    output: |\\\\n      The code parsing functionality is in the `src/core/treeSitter/` directory:\\\\n\\\\n      - `ext2Lang.ts`: Maps file extensions to language types\\\\n      - `lang2Query.ts`: Maps languages to appropriate queries\\\\n      - `languageParser.ts`: Core parsing functionality\\\\n      - `loadLanguage.ts`: Loads language grammars\\\\n      - `parseFile.ts`: Main file parsing entry point\\\\n      - `parseStrategies/`: Language-specific parsing strategies\\\\n      - `queries/`: Tree-sitter queries for different languages\\\\n\\\\n      This module uses tree-sitter to parse code files and extract meaningful information.\\\\n\\\\nmetadata:\\\\n  priority: high\\\\n  version: 1.0\\\\n  tags:\\\\n    - project-structure\\\\n    - organization\\\\n    - development-workflow\\\\n&lt;/rule&gt;\\\\n\\\\n&lt;rule&gt;\\\\nname: project_standards\\\\ndescription: Standards for code quality and organization in the repomix project\\\\nfilters:\\\\n  # Match any file in the project\\\\n  - type: file_extension\\\\n    pattern: \\\\\\\".*\\\\\\\"\\\\n  # Match project initialization events\\\\n  - type: event\\\\n    pattern: \\\\\\\"file_create\\\\\\\"\\\\n\\\\nactions:\\\\n  - type: suggest\\\\n    message: |\\\\n      # Repomix Project Standards\\\\n\\\\n      ## TypeScript Standards\\\\n\\\\n      - **Code Style**: Follow the project's biome.json configuration\\\\n      - **Type Safety**: Strong typing for all functions and classes\\\\n      - **Documentation**: JSDoc comments for public APIs\\\\n      - **Testing**: Comprehensive test coverage with vitest\\\\n\\\\n      ## Project Structure Standards\\\\n\\\\n      - **Module Organization**: Functionality grouped by domain (cli, core, config)\\\\n      - **Component Isolation**: Clear separation of concerns between modules\\\\n      - **Worker Architecture**: CPU-intensive tasks use worker threads\\\\n      - **Error Handling**: Consistent error handling patterns\\\\n\\\\n      ## Web Interface Standards\\\\n\\\\n      - **Frontend**: Vue.js components with TypeScript\\\\n      - **Backend**: Node.js API with TypeScript\\\\n      - **Internationalization**: Support for multiple languages\\\\n      - **Responsive Design**: Mobile and desktop friendly UI\\\\n\\\\n      ## Security Standards\\\\n\\\\n      - **Input Validation**: Validate all user inputs\\\\n      - **File Safety**: Check files for potential security issues\\\\n      - **Permission Checks**: Verify file access permissions\\\\n      - **Rate Limiting**: Prevent abuse of API endpoints\\\\n\\\\n      ## Validation Requirements\\\\n\\\\n      - All code must have appropriate type annotations\\\\n      - All public APIs must have documentation comments\\\\n      - All code must have corresponding tests\\\\n      - All UI components must support internationalization\\\\n      - Security checks must be applied to all file operations\\\\n\\\\nexamples:\\\\n  - input: |\\\\n      # What are the requirements for TypeScript code in this project?\\\\n    output: |\\\\n      TypeScript code in this project must:\\\\n      1. Follow the code style defined in biome.json\\\\n      2. Use strong typing for all functions, variables, and classes\\\\n      3. Include JSDoc comments for public APIs\\\\n      4. Be accompanied by comprehensive tests\\\\n      5. Follow the module organization pattern (cli, core, config, etc.)\\\\n      6. Implement proper error handling\\\\n\\\\n  - input: |\\\\n      # How should I structure a new feature?\\\\n    output: |\\\\n      When adding a new feature:\\\\n\\\\n      1. Identify the appropriate module (cli, core, config, etc.)\\\\n      2. Create new files following the existing naming patterns\\\\n      3. Implement the feature with proper typing and documentation\\\\n      4. Add comprehensive tests in the corresponding test directory\\\\n      5. Update any relevant documentation\\\\n      6. Ensure the feature follows security standards if handling files or user input\\\\n\\\\nmetadata:\\\\n  priority: high\\\\n  version: 1.0\\\\n  tags:\\\\n    - standards\\\\n    - code-quality\\\\n    - organization\\\\n&lt;/rule&gt;\\\\n\\\\n&lt;rule&gt;\\\\nname: repomix_context_extraction\\\\ndescription: Guide for using repomix to extract focused context from repositories\\\\nfilters:\\\\n  - type: message\\\\n    pattern: \\\\\\\"(?i)(extract context|code context|repository context|repomix extract|code explanation|understand code)\\\\\\\"\\\\n  - type: context\\\\n    pattern: \\\\\\\"explain code|understand repository|extract code|code extraction\\\\\\\"\\\\n\\\\nactions:\\\\n  - type: suggest\\\\n    message: |\\\\n      # Repomix Context Extraction Guide\\\\n\\\\n      Repomix is a powerful tool for extracting and summarizing code repositories for LLM consumption. This guide focuses on using repomix to extract only the necessary context to explain how specific functionality works.\\\\n\\\\n      ## Core Principles for Effective Context Extraction\\\\n\\\\n      - **Focused Selection**: Only include files/folders directly relevant to the functionality\\\\n      - **Complete Understanding**: Ensure all dependencies are included for a complete explanation\\\\n      - **XML Output**: Use XML format for structured representation of code\\\\n      - **Minimal Context**: Avoid including unnecessary files that add noise\\\\n      - **Consistent Ignore Patterns**: Use standard ignore patterns for common build artifacts and dependencies\\\\n\\\\n      ## Command Structure\\\\n\\\\n      ```bash\\\\n      repomix extract /path/to/repository --style xml --include \\\\\\\"path/to/relevant/files/**\\\\\\\" --exclude \\\\\\\"tests/**\\\\\\\" --ignore \\\\\\\"**/node_modules,**/dist,**/build\\\\\\\" --output output.xml\\\\n      ```\\\\n\\\\n      ## Key Parameters\\\\n\\\\n      - `--style xml`: Output in XML format for structured representation\\\\n      - `--include`: Specify patterns for files to include (supports glob patterns)\\\\n      - `--exclude`: Specify patterns for files to exclude\\\\n      - `--ignore`: Specify patterns for files to ignore (build artifacts, dependencies)\\\\n      - `--output`: Specify the output file\\\\n      - `--output-show-line-numbers`: Include line numbers in the output (helpful for reference)\\\\n      - `--max-tokens`: Limit the total token count (optional)\\\\n      - `--depth`: Control the depth of directory traversal (optional)\\\\n\\\\n      ## Standard Ignore Patterns\\\\n\\\\n      Always include these standard ignore patterns to avoid including unnecessary files:\\\\n\\\\n      ```bash\\\\n      --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\"\\\\n      ```\\\\n\\\\n      ## Best Practices\\\\n\\\\n      ### 1. Identify Core Components\\\\n\\\\n      Before extraction, identify the core components needed to explain the functionality:\\\\n\\\\n      - Entry point files\\\\n      - Core implementation files\\\\n      - Essential utility functions\\\\n      - Type definitions and interfaces\\\\n      - Configuration files directly related to the functionality\\\\n\\\\n      ### 2. Use Precise Include Patterns\\\\n\\\\n      ```bash\\\\n      # Example: Extract authentication system\\\\n      repomix extract ./repo --style xml --include \\\\\\\"src/auth/**\\\\\\\" --include \\\\\\\"src/models/User.js\\\\\\\" --include \\\\\\\"src/config/auth.js\\\\\\\" --ignore \\\\\\\"**/node_modules,**/dist,**/build,**/package-lock.json\\\\\\\" --output-show-line-numbers --output auth-context.xml\\\\n      ```\\\\n\\\\n      ### 3. Exclude Unnecessary Files\\\\n\\\\n      ```bash\\\\n      # Exclude tests, documentation, and build artifacts\\\\n      repomix extract ./repo --style xml --exclude \\\\\\\"**/*.test.js\\\\\\\" --exclude \\\\\\\"**/*.spec.js\\\\\\\" --exclude \\\\\\\"docs/**\\\\\\\" --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" --output-show-line-numbers --output clean-context.xml\\\\n      ```\\\\n\\\\n      ### 4. Combine With Search When Needed\\\\n\\\\n      For complex functionality spanning multiple directories:\\\\n\\\\n      ```bash\\\\n      # First find relevant files\\\\n      find ./repo -type f -name \\\\\\\"*.js\\\\\\\" | grep -E \\\\\\\"auth|user|permission\\\\\\\" &gt; relevant_files.txt\\\\n\\\\n      # Then use the list with repomix\\\\n      cat relevant_files.txt | xargs -I{} echo \\\\\\\"--include {}\\\\\\\" | xargs repomix extract ./repo --style xml --ignore \\\\\\\"**/node_modules,**/dist,**/build\\\\\\\" --output-show-line-numbers --output auth-system.xml\\\\n      ```\\\\n\\\\n      ### 5. Focus on Interfaces Over Implementation Details\\\\n\\\\n      When explaining how something works, prioritize interface files and core logic over detailed implementations:\\\\n\\\\n      ```bash\\\\n      repomix extract ./repo --style xml --include \\\\\\\"src/api/**/*.interface.ts\\\\\\\" --include \\\\\\\"src/core/**/*.ts\\\\\\\" --exclude \\\\\\\"**/*.impl.ts\\\\\\\" --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" --output-show-line-numbers --output system-overview.xml\\\\n      ```\\\\n\\\\n      ## Example Scenarios\\\\n\\\\n      ### Extracting a Feature Implementation\\\\n\\\\n      ```bash\\\\n      # Extract everything related to the search feature\\\\n      repomix extract ./repo --style xml --include \\\\\\\"src/**/search/**\\\\\\\" --include \\\\\\\"src/models/SearchIndex.js\\\\\\\" --include \\\\\\\"src/utils/searchHelpers.js\\\\\\\" --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" --output-show-line-numbers --output search-feature.xml\\\\n      ```\\\\n\\\\n      ### Extracting an API Endpoint Flow\\\\n\\\\n      ```bash\\\\n      # Extract files related to the user registration flow\\\\n      repomix extract ./repo --style xml --include \\\\\\\"src/controllers/UserController.js\\\\\\\" --include \\\\\\\"src/services/UserService.js\\\\\\\" --include \\\\\\\"src/models/User.js\\\\\\\" --include \\\\\\\"src/validators/userValidation.js\\\\\\\" --ignore \\\\\\\"**/node_modules,**/dist,**/build\\\\\\\" --output-show-line-numbers --output user-registration.xml\\\\n      ```\\\\n\\\\n      ### Extracting Architecture Overview\\\\n\\\\n      ```bash\\\\n      # Extract core architectural files\\\\n      repomix extract ./repo --style xml --include \\\\\\\"src/core/**/*.ts\\\\\\\" --include \\\\\\\"src/types/**/*.ts\\\\\\\" --include \\\\\\\"src/config/**/*.ts\\\\\\\" --exclude \\\\\\\"**/*.test.ts\\\\\\\" --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" --output-show-line-numbers --output architecture.xml\\\\n      ```\\\\n\\\\n      ### Quick Repository Summary\\\\n\\\\n      ```bash\\\\n      # Generate a quick summary of the entire repository\\\\n      npx repomix --style xml --output-show-line-numbers --output output.txt --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\"\\\\n      ```\\\\n\\\\nexamples:\\\\n  - input: |\\\\n      How can I use repomix to extract just the authentication system from my repository?\\\\n    output: |\\\\n      To extract just the authentication system from your repository using repomix with XML output:\\\\n\\\\n      ```bash\\\\n      repomix extract ./your-repo --style xml \\\\\\\\\\\\n        --include \\\\\\\"src/**/auth/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/**/user/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/models/User.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/middleware/auth.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/config/auth.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/*.test.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/*.spec.*\\\\\\\" \\\\\\\\\\\\n        --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" \\\\\\\\\\\\n        --output-show-line-numbers \\\\\\\\\\\\n        --output auth-system.xml\\\\n      ```\\\\n\\\\n      This command:\\\\n      1. Targets all auth-related files and directories\\\\n      2. Includes user-related files that are typically part of authentication\\\\n      3. Includes specific model, middleware, and config files related to auth\\\\n      4. Excludes test files to keep the output focused\\\\n      5. Ignores common build artifacts and dependencies\\\\n      6. Includes line numbers for easier reference\\\\n      7. Outputs in XML format for structured representation\\\\n\\\\n      If you need to be even more selective, first identify the exact files involved:\\\\n\\\\n      ```bash\\\\n      find ./your-repo -type f -name \\\\\\\"*.js\\\\\\\" | grep -E \\\\\\\"auth|login|register|user|permission|role\\\\\\\" | less\\\\n      ```\\\\n\\\\n      Then use those specific files in your include patterns.\\\\n\\\\n  - input: |\\\\n      I need to extract context to explain how the data processing pipeline works in my repo.\\\\n    output: |\\\\n      To extract context that explains how a data processing pipeline works:\\\\n\\\\n      ```bash\\\\n      repomix extract ./your-repo --style xml \\\\\\\\\\\\n        --include \\\\\\\"src/**/pipeline/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/**/processors/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/models/DataModel.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/utils/dataUtils.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/config/pipeline.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/types/data.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/*.test.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/mock*\\\\\\\" \\\\\\\\\\\\n        --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" \\\\\\\\\\\\n        --output-show-line-numbers \\\\\\\\\\\\n        --output data-pipeline.xml\\\\n      ```\\\\n\\\\n      This approach:\\\\n      1. Focuses on pipeline and processor directories\\\\n      2. Includes relevant data models and utilities\\\\n      3. Includes pipeline configuration\\\\n      4. Includes type definitions for data structures\\\\n      5. Excludes tests and mock data\\\\n      6. Ignores common build artifacts and dependencies\\\\n      7. Includes line numbers for easier reference\\\\n\\\\n      For a more comprehensive understanding, you might want to include the entry points:\\\\n\\\\n      ```bash\\\\n      repomix extract ./your-repo --style xml \\\\\\\\\\\\n        --include \\\\\\\"src/index.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/**/pipeline/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/**/processors/**\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/models/DataModel.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/utils/dataUtils.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/config/pipeline.*\\\\\\\" \\\\\\\\\\\\n        --include \\\\\\\"src/types/data.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/*.test.*\\\\\\\" \\\\\\\\\\\\n        --exclude \\\\\\\"**/mock*\\\\\\\" \\\\\\\\\\\\n        --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" \\\\\\\\\\\\n        --output-show-line-numbers \\\\\\\\\\\\n        --output data-pipeline-with-entry.xml\\\\n      ```\\\\n\\\\n      This ensures you capture how the pipeline is initialized and triggered.\\\\n\\\\n  - input: |\\\\n      How do I create a quick summary of my entire repository for an LLM?\\\\n    output: |\\\\n      For a quick summary of your entire repository optimized for LLM consumption:\\\\n\\\\n      ```bash\\\\n      npx repomix --style xml --output-show-line-numbers --output output.txt --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\"\\\\n      ```\\\\n\\\\n      This command:\\\\n      1. Uses repomix to process your repository\\\\n      2. Outputs in XML format for structured representation\\\\n      3. Includes line numbers for easier reference\\\\n      4. Ignores common build artifacts and dependencies\\\\n      5. Creates an output.txt file with the repository summary\\\\n\\\\n      If you want to focus on specific aspects while still getting a broad overview:\\\\n\\\\n      ```bash\\\\n      npx repomix --style xml --include \\\\\\\"src/**/*.ts\\\\\\\" --include \\\\\\\"src/**/*.js\\\\\\\" --exclude \\\\\\\"**/*.test.*\\\\\\\" --ignore \\\\\\\"**/uv.lock,**/package-lock.json,**/.env,**/Cargo.lock,**/node_modules,**/target,**/dist,**/build,**/output.txt,**/yarn.lock\\\\\\\" --output-show-line-numbers --output repo-summary.xml\\\\n      ```\\\\n\\\\n      This will include all TypeScript and JavaScript files while excluding tests and common artifacts.\\\\n\\\\nmetadata:\\\\n  priority: high\\\\n  version: 1.0\\\\n  tags:\\\\n    - context-extraction\\\\n    - code-understanding\\\\n    - repomix-usage\\\\n&lt;/rule&gt;\\\\n\\\"}], \\\"valid_rule_count\\\": 2}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#get_static_cursor_rule","title":"get_static_cursor_rule","text":"<p>Request:</p> <pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"get_static_cursor_rule\",\"arguments\":{\"rule_name\":\"tree\"},\"_meta\":{\"progressToken\":1}}}\n</code></pre> <p>Response:</p> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"rule_name\\\": \\\"tree.mdc.md\\\", \\\"content\\\": \\\"---\\\\ndescription: Display repository structure\\\\nglobs: *\\\\nalwaysApply: false\\\\n---\\\\nWhen the user asks about the project layout, structure, or organization, run the command `tree -L 7 -I \\\\\\\"*.pyc|__pycache__|.git|.pytest_cache|.ruff_cache|.mypy_cache|.coverage|htmlcov|.venv|.env|*.egg-info|build|dist|node_modules|.DS_Store|images\\\\\\\"` to help understand and visualize the repository structure.\\\\n\\\"}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#save_cursor_rule","title":"save_cursor_rule","text":"<pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"save_cursor_rule\",\"arguments\":{\"rule_name\":\"bossjones\",\"rule_content\":\"# Python Best Practices\\\\n\\\\nWhen writing Python code, follow these guidelines:\\\\n\\\\n1. Use type hints\\\\n2. Write docstrings\\\\n3. Follow PEP 8\"},\"_meta\":{\"progressToken\":3}}}\n</code></pre> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"operations\\\": [{\\\"type\\\": \\\"create_directory\\\", \\\"path\\\": \\\"hack/drafts/cursor_rules\\\", \\\"options\\\": {\\\"parents\\\": true, \\\"exist_ok\\\": true}}, {\\\"type\\\": \\\"write_file\\\", \\\"path\\\": \\\"hack/drafts/cursor_rules/bossjones.mdc.md\\\", \\\"content\\\": \\\"# Python Best Practices\\\\\\\\n\\\\\\\\nWhen writing Python code, follow these guidelines:\\\\\\\\n\\\\\\\\n1. Use type hints\\\\\\\\n2. Write docstrings\\\\\\\\n3. Follow PEP 8\\\", \\\"options\\\": {\\\"mode\\\": \\\"w\\\"}}], \\\"message\\\": \\\"Instructions to save cursor rule to hack/drafts/cursor_rules/bossjones.mdc.md\\\"}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#recommend_cursor_rules","title":"recommend_cursor_rules","text":"<pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"recommend_cursor_rules\",\"arguments\":{\"repo_summary\":\"fastapi fastapi fastapi fastapi fastapi fastapi fastapi\"},\"_meta\":{\"progressToken\":5}}}\n</code></pre> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"code-documentation\\\", \\\"description\\\": \\\"Standards for code documentation and comments\\\", \\\"reason\\\": \\\"Improve overall code documentation\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"error-handling\\\", \\\"description\\\": \\\"Best practices for error handling and logging\\\", \\\"reason\\\": \\\"Enhance application reliability with proper error handling\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"fastapi-best-practices\\\", \\\"description\\\": \\\"Best practices for FastAPI development\\\", \\\"reason\\\": \\\"Repository uses FastAPI framework\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"fastapi-security\\\", \\\"description\\\": \\\"Security considerations for FastAPI applications\\\", \\\"reason\\\": \\\"Ensure secure API development with FastAPI\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"fastapi-testing\\\", \\\"description\\\": \\\"Testing strategies for FastAPI endpoints\\\", \\\"reason\\\": \\\"Help with writing comprehensive tests for FastAPI endpoints\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"api-security\\\", \\\"description\\\": \\\"Security considerations for API development\\\", \\\"reason\\\": \\\"Repository implements APIs\\\"}\"},{\"type\":\"text\",\"text\":\"{\\\"name\\\": \\\"api-documentation\\\", \\\"description\\\": \\\"Best practices for API documentation\\\", \\\"reason\\\": \\\"Improve API documentation\\\"}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#prep_workspace","title":"prep_workspace","text":"<pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"prep_workspace\",\"arguments\":{},\"_meta\":{\"progressToken\":6}}}\n</code></pre> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"success\\\", \\\"message\\\": \\\"\\\\nTo prepare the workspace for cursor rules, the following steps are needed:\\\\n\\\\n1. Create the cursor rules directory structure, this should be relative to the repo root eg ./hack/drafts/cursor_rules:\\\\n   mkdir -p ./hack/drafts/cursor_rules .cursor/rules || true\\\\n\\\\n2. Ensure the .cursor/rules directory exists for deployment:\\\\n   mkdir -p .cursor/rules\\\\n   mkdir -p ./hack/drafts/cursor_rules\\\\n\\\\n3. Check if Makefile exists with an update-cursor-rules task:\\\\n   The update-cursor-rules task should copy files from hack/drafts/cursor_rules to .cursor/rules. This command updates Cursor editor rules by copying rule definitions from a drafts directory into the Cursor configuration folder. It first creates a .cursor/rules directory if it doesn't exist. Then it finds all Markdown (.md) files in the hack/drafts/cursor_rules directory (excluding any README files), copies them to the .cursor/rules directory, and preserves their filenames without the .md extension. The comment notes that Cursor doesn't support generating .mdc files directly through the Composer Agent at the time this was written\\\\n\\\\n\\\\n4. Update .dockerignore to exclude the cursor rules drafts directory:\\\\n   Add 'hack/drafts/cursor_rules' to .dockerignore if it exists\\\\n\\\\n5. Write the following mandatory cursor rule files to the client repo's cursor rules stage directory one at a time, using the get_static_cursor_rules function to retrieve each file. when saving the file ensure the file has extension .mdc.md, eg tree.mdc becomes tree.mdc.md:\\\\n   - tree.mdc: A rule for displaying repository structure\\\\n   - repo_analyzer.mdc: A rule for analyzing repository structure and locating code definitions\\\\n   - notify.mdc: A rule for notification at the end of tasks\\\\n   - repomix.mdc: A rule for repository summarization and packaging for LLM consumption\\\\n   - cursor_rules_location.mdc: A rule for locating the cursor rules directory and how to write them\\\\n\\\\n6. Update the client repo's .cursor/mcp.json file to include new entries if they don't already exist:\\\\n   Ensure the .cursor/mcp.json file contains entries for prompt_library and sequentialthinking:\\\\n   ```json\\\\n   {\\\\n     \\\\\\\"prompt_library\\\\\\\": {\\\\n       \\\\\\\"command\\\\\\\": \\\\\\\"uv\\\\\\\",\\\\n       \\\\\\\"args\\\\\\\": [\\\\n         \\\\\\\"run\\\\\\\",\\\\n         \\\\\\\"--with\\\\\\\",\\\\n         \\\\\\\"mcp[cli]\\\\\\\",\\\\n         \\\\\\\"mcp\\\\\\\",\\\\n         \\\\\\\"run\\\\\\\",\\\\n         \\\\\\\"${PWD}/src/codegen_lab/prompt_library.py\\\\\\\"\\\\n       ]\\\\n     },\\\\n     \\\\\\\"sequentialthinking\\\\\\\": {\\\\n       \\\\\\\"command\\\\\\\": \\\\\\\"npx\\\\\\\",\\\\n       \\\\\\\"args\\\\\\\": [\\\\n         \\\\\\\"-y\\\\\\\",\\\\n         \\\\\\\"@modelcontextprotocol/server-sequential-thinking\\\\\\\"\\\\n       ]\\\\n     }\\\\n   }\\\\n   ```\\\\n   Note: The path in the prompt_library entry should be adjusted to use the actual project path (PWD) instead of hardcoded paths.\\\\n\\\", \\\"directory_exists\\\": true, \\\"directory_path\\\": \\\"./hack/drafts/cursor_rules\\\", \\\"mkdir_command\\\": \\\"mkdir -p ./hack/drafts/cursor_rules .cursor/rules || true\\\", \\\"directory_structure\\\": \\\"Directory structure to create at ./hack/drafts/cursor_rules\\\", \\\"workspace_prepared\\\": false, \\\"workspace_result\\\": {\\\"status\\\": \\\"success\\\", \\\"message\\\": \\\"Instructions provided for workspace preparation at ./hack/drafts/cursor_rules\\\", \\\"directory_exists\\\": true, \\\"directory_path\\\": \\\"./hack/drafts/cursor_rules\\\", \\\"mkdir_command\\\": \\\"mkdir -p ./hack/drafts/cursor_rules .cursor/rules || true\\\"}}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#create_cursor_rule_files","title":"create_cursor_rule_files","text":"<pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"create_cursor_rule_files\",\"arguments\":{\"rule_names\":[\"bossjones\"]},\"_meta\":{\"progressToken\":7}}}\n</code></pre> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"success\\\": true, \\\"operations\\\": [{\\\"type\\\": \\\"create_directory\\\", \\\"path\\\": \\\"hack/drafts/cursor_rules\\\", \\\"options\\\": {\\\"parents\\\": true, \\\"exist_ok\\\": true}}, {\\\"type\\\": \\\"write_file\\\", \\\"path\\\": \\\"hack/drafts/cursor_rules/bossjones.mdc.md\\\", \\\"content\\\": \\\"\\\", \\\"options\\\": {\\\"mode\\\": \\\"w\\\"}}], \\\"created_files\\\": [\\\"bossjones.mdc.md\\\"], \\\"touch_command\\\": \\\"touch hack/drafts/cursor_rules/bossjones.mdc.md\\\", \\\"next_steps\\\": \\\"\\\\nNext steps:\\\\n1. Write content to each file sequentially\\\\n2. Deploy the rules using 'make update-cursor-rules'\\\\n3. Verify the rules are correctly deployed to .cursor/rules\\\\n\\\", \\\"message\\\": \\\"Instructions to create 1 empty cursor rule files in hack/drafts/cursor_rules. \\\\nNext steps:\\\\n1. Write content to each file sequentially\\\\n2. Deploy the rules using 'make update-cursor-rules'\\\\n3. Verify the rules are correctly deployed to .cursor/rules\\\\n\\\"}\"}],\"isError\":false}\n</code></pre>"},{"location":"mcp-servers/prompt_library_mcp/#ensure_makefile_task","title":"ensure_makefile_task","text":"<pre><code>{\"method\":\"tools/call\",\"params\":{\"name\":\"ensure_makefile_task\",\"arguments\":{\"makefile_path\":\"Makefile\"},\"_meta\":{\"progressToken\":8}}}\n</code></pre> <pre><code>{\"content\":[{\"type\":\"text\",\"text\":\"{\\\"operations\\\": [{\\\"type\\\": \\\"check_file_exists\\\", \\\"path\\\": \\\"Makefile\\\"}, {\\\"type\\\": \\\"read_file\\\", \\\"path\\\": \\\"Makefile\\\", \\\"options\\\": {\\\"encoding\\\": \\\"utf-8\\\"}}], \\\"requires_result\\\": true, \\\"message\\\": \\\"Instructions to check Makefile and update if needed\\\", \\\"update_task_content\\\": \\\"\\\\n# Cursor Rules\\\\n.PHONY: update-cursor-rules\\\\nupdate-cursor-rules:  ## Update cursor rules from prompts/drafts/cursor_rules\\\\n\\\\t# Create .cursor/rules directory if it doesn't exist.\\\\n\\\\t# Note: at the time of writing, cursor does not support generating .mdc files via Composer Agent.s\\\\n\\\\tmkdir -p .cursor/rules || true\\\\n\\\\t# Copy files from hack/prompts/drafts/cursor_rules to .cursor/rules and change extension to .mdc\\\\n\\\\t# Exclude README.md files from being copied\\\\n\\\\tfind hack/drafts/cursor_rules -type f -name \\\\\\\"*.md\\\\\\\" ! -name \\\\\\\"README.md\\\\\\\" -exec sh -c 'for file; do target=$${file%.md}; cp -a \\\\\\\"$$file\\\\\\\" \\\\\\\".cursor/rules/$$(basename \\\\\\\"$$target\\\\\\\")\\\\\\\"; done' sh {} +\\\\n\\\", \\\"next_steps\\\": \\\"After applying these operations, you'll need to check if the Makefile exists and contains the update-cursor-rules task, then update or create it accordingly.\\\"}\"}],\"isError\":false}\n</code></pre>"},{"location":"tools/cursor-rules/","title":"Cursor Rules for Iterative Development","text":""},{"location":"tools/cursor-rules/#overview","title":"Overview","text":"<p>This document describes the collection of Cursor rules implemented for Harper Reed's iterative development workflow. These rules help automate and guide developers through the process of working with existing codebases in a structured, incremental manner.</p>"},{"location":"tools/cursor-rules/#what-are-cursor-rules","title":"What are Cursor Rules?","text":"<p>Cursor rules are custom instructions for Cursor's AI assistant that help automate repetitive tasks, enforce best practices, and guide you through complex workflows. They're defined in <code>.mdc.md</code> files and are triggered based on specific patterns in your messages or the files you're working with.</p>"},{"location":"tools/cursor-rules/#rule-collection-for-iterative-development","title":"Rule Collection for Iterative Development","text":"<p>This collection implements Harper Reed's non-greenfield iteration workflow as described in their blog post. The workflow is specifically designed for working with existing codebases rather than greenfield (new) projects.</p>"},{"location":"tools/cursor-rules/#workflow-philosophy","title":"Workflow Philosophy","text":"<p>Harper's non-greenfield iteration workflow involves:</p> <ol> <li>Getting context from the existing codebase</li> <li>Planning per task rather than for the entire project</li> <li>Implementing incrementally with constant testing and feedback</li> <li>Debugging and fixing issues as they arise</li> </ol>"},{"location":"tools/cursor-rules/#rules-in-this-collection","title":"Rules in this Collection","text":"<p>This collection contains the following cursor rules:</p> <ol> <li>Incremental Task Planner - Breaks down a development task into smaller, manageable steps for incremental implementation</li> <li>Code Context Gatherer - Efficiently gathers code context from the codebase for LLM consumption</li> <li>Test Generator - Identifies missing tests and generates appropriate test cases for the codebase</li> <li>Iterative Debug and Fix - Provides guidance for debugging and fixing issues that arise during iterative development</li> <li>Iterative Development Workflow - Master rule that provides a structured workflow for incremental development in existing codebases</li> </ol>"},{"location":"tools/cursor-rules/#detailed-rule-descriptions","title":"Detailed Rule Descriptions","text":""},{"location":"tools/cursor-rules/#1-incremental-task-planner","title":"1. Incremental Task Planner","text":"<p>Purpose: Help break down a development task into smaller, manageable steps for incremental implementation.</p> <p>When to use: When you need to plan the implementation of a new feature or bug fix in an existing codebase.</p> <p>Activation phrases: - \"Plan this feature\" - \"Break down this task\" - \"Help me implement this incrementally\" - \"Steps for adding [feature]\"</p> <p>What it does: - Analyzes the task requirements - Identifies relevant parts of the codebase - Breaks the task into small, logical steps - Creates a todo checklist - Plans for testing - Provides implementation guidance</p>"},{"location":"tools/cursor-rules/#2-code-context-gatherer","title":"2. Code Context Gatherer","text":"<p>Purpose: Efficiently gather code context from the codebase for LLM consumption.</p> <p>When to use: When you need to understand how a specific part of the codebase works.</p> <p>Activation phrases: - \"Help me understand this code\" - \"Gather context for [feature/component]\" - \"How does [system/feature] work?\" - \"Explain the existing code\"</p> <p>What it does: - Identifies relevant components and files - Efficiently collects context from key files - Organizes the context in a logical structure - Summarizes architecture and key patterns - Highlights potential areas for modification</p>"},{"location":"tools/cursor-rules/#3-test-generator","title":"3. Test Generator","text":"<p>Purpose: Identify missing tests and generate appropriate test cases for the codebase.</p> <p>When to use: When you need to improve test coverage for an existing component.</p> <p>Activation phrases: - \"Generate tests for [component]\" - \"We need tests for [feature]\" - \"Add missing test coverage\" - \"Write tests for this code\"</p> <p>What it does: - Analyzes the code for testable components - Determines appropriate test types (unit, integration, etc.) - Follows the project's testing patterns - Generates comprehensive test cases - Includes edge cases and error conditions - Implements tests with proper typing and documentation</p>"},{"location":"tools/cursor-rules/#4-iterative-debug-and-fix","title":"4. Iterative Debug and Fix","text":"<p>Purpose: Provide guidance for debugging and fixing issues that arise during iterative development.</p> <p>When to use: When you encounter a bug or an issue in your implementation.</p> <p>Activation phrases: - \"Debug this issue\" - \"Fix this error\" - \"This isn't working correctly\" - \"Help me troubleshoot [problem]\"</p> <p>What it does: - Helps gather comprehensive error information - Guides you through reproducing and isolating the issue - Provides a systematic approach to debugging - Assists in testing hypotheses about the root cause - Helps design and implement targeted fixes - Guides verification and regression testing - Suggests preventative measures for the future</p>"},{"location":"tools/cursor-rules/#5-iterative-development-workflow","title":"5. Iterative Development Workflow","text":"<p>Purpose: Provide a structured workflow for incremental development in existing codebases.</p> <p>When to use: When you want guidance on the overall process of implementing a feature or fix.</p> <p>Activation phrases: - \"Help me develop this feature\" - \"Guide me through implementing [feature]\" - \"What's the workflow for adding [feature]\" - \"Non-greenfield development process\"</p> <p>What it does: - Guides you through the three phases of iterative development:   1. Understand and Plan   2. Implement Incrementally   3. Refine and Complete - Provides structured steps for each phase - Helps maintain focus on incremental progress - Ensures quality through testing and refactoring</p>"},{"location":"tools/cursor-rules/#how-to-use-these-rules","title":"How to Use These Rules","text":""},{"location":"tools/cursor-rules/#installation","title":"Installation","text":"<p>To use these rules in your project:</p> <ol> <li> <p>Ensure you have a <code>.cursor/rules/</code> directory in your project root:    <pre><code>mkdir -p .cursor/rules\n</code></pre></p> </li> <li> <p>Copy the rule files from the source location:    <pre><code>cp hack/drafts/cursor_rules/*.mdc.md .cursor/rules/\n</code></pre></p> </li> </ol>"},{"location":"tools/cursor-rules/#usage-flow","title":"Usage Flow","text":"<p>Here's how you might use these rules in a typical development session:</p> <ol> <li>Start with the workflow: \"Help me implement a feature using the iterative development workflow\"</li> <li>Gather context: \"Help me understand the current authentication system\"</li> <li>Plan your task: \"Break down the task of adding two-factor authentication\"</li> <li>Implement incrementally: \"Help me implement the first step of the 2FA feature\"</li> <li>Add tests: \"Generate tests for the 2FA authentication code\"</li> <li>Debug issues: \"The 2FA verification isn't working, help me debug it\"</li> </ol>"},{"location":"tools/cursor-rules/#example-conversations","title":"Example Conversations","text":""},{"location":"tools/cursor-rules/#example-1-planning-a-new-feature","title":"Example 1: Planning a New Feature","text":"<p>You: \"I need to add a new payment method to our existing e-commerce system.\"</p> <p>Cursor Assistant: [Using Incremental Task Planner rule] \"I'll help you break that down into manageable steps...\"</p>"},{"location":"tools/cursor-rules/#example-2-understanding-existing-code","title":"Example 2: Understanding Existing Code","text":"<p>You: \"I need to understand how our user authentication system works.\"</p> <p>Cursor Assistant: [Using Code Context Gatherer rule] \"Let me gather the relevant code and explain how it works...\"</p>"},{"location":"tools/cursor-rules/#example-3-adding-tests","title":"Example 3: Adding Tests","text":"<p>You: \"We need to add tests for our newly implemented payment service.\"</p> <p>Cursor Assistant: [Using Test Generator rule] \"I'll help you generate comprehensive tests for the payment service...\"</p>"},{"location":"tools/cursor-rules/#example-4-fixing-an-issue","title":"Example 4: Fixing an Issue","text":"<p>You: \"The payment processing is failing when users have special characters in their names.\"</p> <p>Cursor Assistant: [Using Iterative Debug and Fix rule] \"Let's debug this issue systematically...\"</p>"},{"location":"tools/cursor-rules/#customizing-the-rules","title":"Customizing the Rules","text":"<p>You can customize these rules by editing the <code>.mdc.md</code> files in your <code>.cursor/rules/</code> directory:</p> <ol> <li>Modify the filters to match your specific project patterns</li> <li>Adjust the instructions to align with your team's practices</li> <li>Add or modify examples to better match your codebase</li> </ol>"},{"location":"tools/cursor-rules/#credits","title":"Credits","text":"<p>These rules are based on Harper Reed's blog post \"My LLM codegen workflow atm\" which describes an effective iterative development workflow using LLMs.</p>"},{"location":"tools/uv-workspace/","title":"UV Workspace Management","text":"<p>This document provides documentation for working with UV workspaces in this project. UV workspaces allow you to manage multiple Python packages within a single repository, with proper dependency management and isolation.</p>"},{"location":"tools/uv-workspace/#quick-reference","title":"Quick Reference","text":"Command Description <code>make uv-workspace-lock</code> Update lockfile for entire workspace <code>make uv-workspace-sync</code> Install dependencies for workspace root <code>make uv-workspace-package-sync package=name</code> Install dependencies for specific package <code>make uv-workspace-run package=name cmd=\"command\"</code> Run command in specific package <code>make uv-workspace-init-package name=new-package</code> Initialize a new package <code>make uv-workspace-add-dep package=name</code> Add package as workspace dependency"},{"location":"tools/uv-workspace/#what-is-a-uv-workspace","title":"What is a UV Workspace?","text":"<p>UV Workspace is a feature of the UV package manager that allows for managing multiple packages within a single repository. Benefits include:</p> <ul> <li>Single lockfile for the entire workspace</li> <li>Proper isolation between packages</li> <li>Ability to develop interdependent packages locally</li> <li>Simplified dependency management</li> </ul>"},{"location":"tools/uv-workspace/#workspace-structure","title":"Workspace Structure","text":"<p>Our workspace is structured as follows:</p> <pre><code>codegen-lab/\n\u251c\u2500\u2500 pyproject.toml       # Workspace root config\n\u251c\u2500\u2500 packages/            # Directory containing workspace packages\n\u2502   \u251c\u2500\u2500 package-a/       # Individual package\n\u2502   \u2502   \u251c\u2500\u2500 pyproject.toml\n\u2502   \u2502   \u2514\u2500\u2500 src/\n\u2502   \u2502       \u2514\u2500\u2500 package_a/\n\u2502   \u2502           \u2514\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 cursor-rules-mcp-server/  # Example package\n\u2502       \u251c\u2500\u2500 pyproject.toml\n\u2502       \u2514\u2500\u2500 src/\n\u2502           \u2514\u2500\u2500 cursor_rules_mcp_server/\n\u2502               \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 codegen_lab/     # Workspace root package\n        \u2514\u2500\u2500 __init__.py\n</code></pre>"},{"location":"tools/uv-workspace/#available-commands","title":"Available Commands","text":"<p>These commands are available in the Makefile to help you work with UV workspaces:</p>"},{"location":"tools/uv-workspace/#core-workspace-management-commands","title":"Core Workspace Management Commands","text":""},{"location":"tools/uv-workspace/#update-lockfile-for-the-entire-workspace","title":"Update Lockfile for the Entire Workspace","text":"<pre><code>make uv-workspace-lock\n</code></pre> <p>This command updates the lockfile for the entire workspace, resolving all dependencies across all packages and ensuring they work well together.</p>"},{"location":"tools/uv-workspace/#install-dependencies-for-the-workspace-root","title":"Install Dependencies for the Workspace Root","text":"<pre><code>make uv-workspace-sync\n</code></pre> <p>This command installs all dependencies required by the workspace root package.</p>"},{"location":"tools/uv-workspace/#install-dependencies-for-a-specific-package","title":"Install Dependencies for a Specific Package","text":"<pre><code>make uv-workspace-package-sync package=cursor-rules-mcp-server\n</code></pre> <p>This command installs all dependencies required by a specific package. Replace <code>cursor-rules-mcp-server</code> with the name of your package.</p>"},{"location":"tools/uv-workspace/#run-a-command-in-a-specific-package","title":"Run a Command in a Specific Package","text":"<pre><code>make uv-workspace-run package=cursor-rules-mcp-server cmd=\"python -m cursor_rules_mcp_server\"\n</code></pre> <p>This command runs a specified command within the context of a specific package. Replace <code>cursor-rules-mcp-server</code> with the name of your package and <code>python -m cursor_rules_mcp_server</code> with the command you want to run.</p>"},{"location":"tools/uv-workspace/#package-management-utilities","title":"Package Management Utilities","text":""},{"location":"tools/uv-workspace/#initialize-a-new-package-in-the-workspace","title":"Initialize a New Package in the Workspace","text":"<pre><code>make uv-workspace-init-package name=new-package\n</code></pre> <p>This command initializes a new package in the workspace with the following: - Creates the proper directory structure under <code>packages/new-package/</code> - Generates a basic <code>pyproject.toml</code> file with required fields - Creates an initial <code>__init__.py</code> file - Adds a <code>README.md</code> file</p> <p>After running this command, you'll need to add the package as a workspace dependency in the root <code>pyproject.toml</code> file, which can be done with the command below.</p>"},{"location":"tools/uv-workspace/#add-a-workspace-package-as-a-dependency-to-the-root","title":"Add a Workspace Package as a Dependency to the Root","text":"<pre><code>make uv-workspace-add-dep package=new-package\n</code></pre> <p>This command adds a workspace package as a dependency to the root <code>pyproject.toml</code> file. After running this command, you should run <code>make uv-workspace-lock</code> to update the lockfile.</p>"},{"location":"tools/uv-workspace/#working-with-workspace-packages","title":"Working with Workspace Packages","text":""},{"location":"tools/uv-workspace/#creating-a-new-package","title":"Creating a New Package","text":"<ol> <li> <p>Initialize the package:    <pre><code>make uv-workspace-init-package name=my-new-package\n</code></pre></p> </li> <li> <p>Add it as a workspace dependency:    <pre><code>make uv-workspace-add-dep package=my-new-package\n</code></pre></p> </li> <li> <p>Update the lockfile:    <pre><code>make uv-workspace-lock\n</code></pre></p> </li> </ol>"},{"location":"tools/uv-workspace/#developing-across-packages","title":"Developing Across Packages","text":"<p>If you need to use one workspace package in another:</p> <ol> <li> <p>Add the dependency in the package's <code>pyproject.toml</code>:    <pre><code>[project]\ndependencies = [\n    \"other-workspace-package\",\n]\n</code></pre></p> </li> <li> <p>Run the workspace lock to update dependencies:    <pre><code>make uv-workspace-lock\n</code></pre></p> </li> </ol>"},{"location":"tools/uv-workspace/#running-tests-for-a-specific-package","title":"Running Tests for a Specific Package","text":"<pre><code>make uv-workspace-run package=my-package cmd=\"pytest\"\n</code></pre>"},{"location":"tools/uv-workspace/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tools/uv-workspace/#dependency-resolution-issues","title":"Dependency Resolution Issues","text":"<p>If you encounter dependency resolution issues:</p> <ol> <li> <p>Make sure all workspace packages have compatible Python version requirements:    <pre><code>grep \"requires-python\" packages/*/pyproject.toml\n</code></pre></p> </li> <li> <p>Try reinstalling all dependencies:    <pre><code>make uv-workspace-sync\n</code></pre></p> </li> </ol>"},{"location":"tools/uv-workspace/#package-not-found","title":"Package Not Found","text":"<p>If a workspace package cannot be imported:</p> <ol> <li> <p>Verify it's properly added to the workspace sources in root <code>pyproject.toml</code>:    <pre><code>[tool.uv.sources]\nmy-package = { workspace = true }\n</code></pre></p> </li> <li> <p>Ensure the package directory structure follows the convention:    <pre><code>packages/my-package/src/my_package/__init__.py\n</code></pre></p> </li> </ol>"},{"location":"tools/uv-workspace/#further-reading","title":"Further Reading","text":"<ul> <li>UV Package Manager Documentation</li> <li>UV Workspace Documentation</li> </ul>"},{"location":"user-guide/configuration/","title":"Configuration","text":"<p>This page explains how to configure Codegen Lab for your specific needs.</p>"},{"location":"user-guide/configuration/#configuration-file","title":"Configuration File","text":"<p>Codegen Lab uses a YAML-based configuration file located at <code>config.yaml</code> in the project root directory. You can also specify a custom configuration file path when running Codegen Lab.</p>"},{"location":"user-guide/configuration/#example-configuration","title":"Example Configuration","text":"<pre><code># Basic configuration\nname: \"My Codegen Project\"\nversion: \"1.0.0\"\n\n# Environment settings\nenvironment:\n  python_version: \"3.12.0\"\n  cuda_support: true\n  debug_mode: false\n\n# Model settings\nmodel:\n  name: \"gpt-4\"\n  temperature: 0.7\n  max_tokens: 2048\n  top_p: 0.95\n\n# Paths\npaths:\n  output_dir: \"./generated\"\n  templates_dir: \"./templates\"\n  cache_dir: \"./.cache\"\n\n# Logging\nlogging:\n  level: \"INFO\"\n  file: \"./logs/codegen.log\"\n  rotation: \"daily\"\n</code></pre>"},{"location":"user-guide/configuration/#configuration-options","title":"Configuration Options","text":""},{"location":"user-guide/configuration/#basic-configuration","title":"Basic Configuration","text":"Option Description Default <code>name</code> Project name \"Codegen Project\" <code>version</code> Project version \"0.1.0\""},{"location":"user-guide/configuration/#environment-settings","title":"Environment Settings","text":"Option Description Default <code>environment.python_version</code> Python version to use \"3.10.0\" <code>environment.cuda_support</code> Enable CUDA support false <code>environment.debug_mode</code> Enable debug mode false"},{"location":"user-guide/configuration/#model-settings","title":"Model Settings","text":"Option Description Default <code>model.name</code> Model to use \"gpt-3.5-turbo\" <code>model.temperature</code> Temperature parameter 0.7 <code>model.max_tokens</code> Maximum tokens to generate 1024 <code>model.top_p</code> Top-p sampling parameter 0.9"},{"location":"user-guide/configuration/#paths","title":"Paths","text":"Option Description Default <code>paths.output_dir</code> Output directory \"./generated\" <code>paths.templates_dir</code> Templates directory \"./templates\" <code>paths.cache_dir</code> Cache directory \"./.cache\""},{"location":"user-guide/configuration/#logging","title":"Logging","text":"Option Description Default <code>logging.level</code> Logging level \"INFO\" <code>logging.file</code> Log file path \"./logs/codegen.log\" <code>logging.rotation</code> Log rotation \"daily\""},{"location":"user-guide/configuration/#environment-variables","title":"Environment Variables","text":"<p>Configuration can also be specified using environment variables. Environment variables take precedence over config file settings.</p> Environment Variable Config Equivalent Description <code>CODEGEN_MODEL_NAME</code> <code>model.name</code> Model to use <code>CODEGEN_MODEL_TEMP</code> <code>model.temperature</code> Temperature parameter <code>CODEGEN_DEBUG</code> <code>environment.debug_mode</code> Enable debug mode <code>CODEGEN_OUTPUT_DIR</code> <code>paths.output_dir</code> Output directory <code>CODEGEN_LOG_LEVEL</code> <code>logging.level</code> Logging level"},{"location":"user-guide/configuration/#command-line-arguments","title":"Command Line Arguments","text":"<p>Most configuration options can also be set via command line arguments. Command line arguments take precedence over both environment variables and config file settings.</p> <pre><code>python -m codegen_lab --model gpt-4 --temperature 0.8 --debug --output-dir ./custom_output\n</code></pre>"},{"location":"user-guide/configuration/#uv-workspace-configuration","title":"UV Workspace Configuration","text":"<p>Codegen Lab uses UV workspaces to manage multiple packages within a single repository. The workspace configuration is defined in the root <code>pyproject.toml</code> file.</p>"},{"location":"user-guide/configuration/#root-pyprojecttoml-configuration","title":"Root pyproject.toml Configuration","text":"<p>The root <code>pyproject.toml</code> file contains the configuration for the entire workspace:</p> <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"codegen-lab\"\nversion = \"0.1.0\"\ndescription = \"A toolkit for AI-assisted code generation and development\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"better-exceptions&gt;=0.3.3\",\n]\n\n# UV Workspace Configuration\n[tool.uv.sources]\n# Workspace packages\ncursor-rules-mcp-server = { workspace = true }\n# Add other packages here\n</code></pre>"},{"location":"user-guide/configuration/#workspace-package-configuration","title":"Workspace Package Configuration","text":"<p>Each package in the <code>packages</code> directory has its own <code>pyproject.toml</code> file:</p> <pre><code>[project]\nname = \"cursor-rules-mcp-server\"\nversion = \"0.1.0\"\ndescription = \"Cursor rules MCP server package\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"better-exceptions&gt;=0.3.3\",\n]\n\n[build-system]\nrequires = [\"setuptools&gt;=61\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools]\npackage-dir = {\"\" = \"src\"}\npackages = [\"cursor_rules_mcp_server\"]\n</code></pre>"},{"location":"user-guide/configuration/#workspace-dependencies","title":"Workspace Dependencies","text":"<p>To use one workspace package as a dependency in another, add it to the dependencies list:</p> <pre><code>[project]\ndependencies = [\n    \"another-workspace-package\",\n]\n</code></pre> <p>Then update the workspace lockfile:</p> <pre><code>make uv-workspace-lock\n</code></pre> <p>For more detailed information about working with UV workspaces, refer to the UV Workspace documentation.</p>"},{"location":"user-guide/docs-automation/","title":"Documentation Automation","text":"<p>This guide explains how Codegen Lab's documentation server is automated to prevent port conflicts and simplify the development workflow.</p>"},{"location":"user-guide/docs-automation/#automatic-port-management","title":"Automatic Port Management","text":"<p>The <code>make docs-serve</code> command now includes automatic port management, featuring:</p> <ol> <li>Automatic Process Detection: The system automatically detects if a MkDocs server is already running on port 8000</li> <li>Process Termination: If requested (with the <code>--kill-existing</code> flag), it automatically terminates existing MkDocs processes</li> <li>Alternative Port Selection: If killing is not possible or not requested, it finds an available port automatically</li> <li>Clear Status Messages: The system provides clear messages about what it's doing and which port it's using</li> </ol>"},{"location":"user-guide/docs-automation/#usage","title":"Usage","text":""},{"location":"user-guide/docs-automation/#basic-usage","title":"Basic Usage","text":"<p>To start the documentation server with automatic port management:</p> <pre><code>make docs-serve\n</code></pre> <p>This will: - Use port 8000 if available - Kill any existing MkDocs processes on port 8000 if found - Fall back to an alternative port if needed</p>"},{"location":"user-guide/docs-automation/#custom-options","title":"Custom Options","text":"<p>You can customize the behavior by running the script directly:</p> <pre><code>uv run python scripts/serve_docs.py --no-kill-existing --port 8080\n</code></pre> <p>Available options: - <code>--port PORT</code>: Specify a custom port (default: 8000) - <code>--kill-existing</code>: Kill existing MkDocs processes on the port (default) - <code>--no-kill-existing</code>: Don't kill existing processes, use an alternative port instead - <code>--no-gh-deploy-url</code>: Don't use GitHub Pages URL in configuration (useful for local development) - <code>--clean</code>: Clean the build directory before building - <code>--build-only</code>: Only build the documentation, don't serve it</p>"},{"location":"user-guide/docs-automation/#how-it-works","title":"How It Works","text":"<p>The automation script (<code>scripts/serve_docs.py</code>) performs the following steps:</p> <ol> <li>Checks if the requested port is already in use</li> <li>Identifies any MkDocs processes running on that port</li> <li>If <code>--kill-existing</code> is set, attempts to terminate those processes</li> <li>If the port is still unavailable, scans for an available port</li> <li>Starts the MkDocs server with the appropriate configuration</li> <li>Provides clear terminal output about what's happening</li> </ol>"},{"location":"user-guide/docs-automation/#graceful-termination","title":"Graceful Termination","text":"<p>The script also handles interruption gracefully. When you press Ctrl+C:</p> <ol> <li>The script catches the keyboard interrupt</li> <li>It sends a graceful termination signal to the MkDocs process</li> <li>It ensures clean exit of all processes</li> </ol> <p>This prevents orphaned processes that might cause port conflicts in the future.</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This page provides detailed installation instructions for Codegen Lab.</p>"},{"location":"user-guide/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: macOS, Linux, or Windows</li> <li>Python: Version 3.10 or higher</li> <li>Disk Space: At least 500MB of free disk space</li> <li>Memory: Minimum 4GB RAM recommended</li> </ul>"},{"location":"user-guide/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"user-guide/installation/#method-1-using-uv-recommended","title":"Method 1: Using UV (Recommended)","text":"<p>UV is the preferred package manager for Codegen Lab.</p> <pre><code># Clone the repository\ngit clone https://github.com/bossjones/codegen-lab.git\ncd codegen-lab\n\n# Create and activate virtual environment\nuv venv --python 3.12.0\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies\nuv sync --frozen\n</code></pre>"},{"location":"user-guide/installation/#working-with-uv-workspace","title":"Working with UV Workspace","text":"<p>Codegen Lab is structured as a UV workspace, allowing management of multiple packages within a single repository.</p> <pre><code># Install dependencies for the workspace root\nmake uv-workspace-sync\n\n# Install dependencies for a specific package\nmake uv-workspace-package-sync package=cursor-rules-mcp-server\n\n# Run a command in context of a specific package\nmake uv-workspace-run package=cursor-rules-mcp-server cmd=\"python -m cursor_rules_mcp_server\"\n</code></pre> <p>For detailed information about UV workspace management, refer to the UV Workspace documentation.</p>"},{"location":"user-guide/installation/#method-2-using-pip","title":"Method 2: Using pip","text":"<p>While UV is recommended, you can also use pip for installation.</p> <pre><code># Clone the repository\ngit clone https://github.com/bossjones/codegen-lab.git\ncd codegen-lab\n\n# Create and activate virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Install dependencies\npip install -e .\n</code></pre>"},{"location":"user-guide/installation/#method-3-docker","title":"Method 3: Docker","text":"<p>For containerized deployment, you can use Docker.</p> <pre><code># Build the Docker image\ndocker build -t codegen-lab .\n\n# Run the container\ndocker run -it codegen-lab\n</code></pre>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":""},{"location":"user-guide/installation/#issue-1-dependency-conflict","title":"Issue 1: Dependency Conflict","text":"<p>If you encounter dependency conflicts during installation, try:</p> <pre><code>uv sync --frozen --reinstall\n</code></pre>"},{"location":"user-guide/installation/#issue-2-python-version","title":"Issue 2: Python Version","text":"<p>If your Python version is too old, update your Python installation or use a tool like pyenv to manage multiple Python versions.</p>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter any issues during installation, please:</p> <ol> <li>Check the Troubleshooting Guide</li> <li>Open an issue on the GitHub repository</li> </ol>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/","title":"How to Auto-Generate Cursor Rules for Your Repository","text":"<p>This guide will walk you through the process of automatically generating custom cursor rules for your repository using AI. These steps are designed to be simple enough for anyone to follow.</p>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#what-youll-need","title":"What You'll Need","text":"<ul> <li>Cursor AI editor</li> <li>A GitHub repository you want to create cursor rules for</li> <li>Access to the prompt_library and sequentialthinking MCP servers</li> </ul>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#step-1-generate-a-repository-report","title":"Step 1: Generate a Repository Report","text":"<p>First, we need to analyze your repository to understand its structure and technologies.</p> <ol> <li>Open your repository in Cursor AI</li> <li>Ask Cursor to analyze your repository using the repo_analyzer cursor rule</li> </ol> <p>Example prompt: <pre><code>Can you analyze this repository and create a comprehensive report about its structure, technologies, and patterns? Please use the @repo_analyzer.mdc cursor rule to guide your analysis.\n</code></pre></p>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#detailed-example-analyzing-a-zsh-dotfiles-repository","title":"Detailed Example: Analyzing a ZSH Dotfiles Repository","text":"<p>Note: The following zsh-dotfiles repository analysis is provided as a reference example only. You should adapt these approaches to your specific repository and its technologies. The specific files, directories, and technologies mentioned are unique to this example repository.</p> <p>Here's a real example of how to analyze a repository step by step:</p> <p>Initial request: <pre><code>Please analyze the `zsh-dotfiles` repository and generate a report named `zsh_dotfiles_report.md`, which will detail the technologies used in the repository.\n</code></pre></p> <p>Cursor will begin by examining the repository structure. You can help it by suggesting specific approaches:</p> <pre><code>Let's start by visualizing the directory structure using the `tree` command while excluding specific file types and directories.\n</code></pre> <p>As Cursor analyzes the repository, it will:</p> <ol> <li>Retrieve and analyze key files like:</li> <li><code>Makefile</code></li> <li><code>.pre-commit-config.yaml</code></li> <li><code>requirements-test.txt</code></li> <li><code>README.md</code></li> <li>Configuration files (<code>.zshrc</code>, <code>.chezmoi.yaml.tmpl</code>, etc.)</li> <li> <p>Test files (<code>test_dotfiles.py</code>, <code>conftest.py</code>)</p> </li> <li> <p>Examine specific configuration directories:</p> </li> <li><code>home/dot_sheldon</code> for plugin management</li> <li><code>home/shell/config.zsh</code> for ZSH settings</li> <li> <p><code>home/shell/customs/aliases.zsh</code> for custom functions</p> </li> <li> <p>Check installation scripts:</p> </li> <li><code>home/.chezmoiscripts/run_onchange_before_02-macos-install-sheldon.sh.tmpl</code></li> <li><code>home/.chezmoiscripts/run_onchange_before_01-ubuntu-install-packages.sh.tmpl</code></li> </ol> <p>The final report will include: - Overview of the repository - Repository structure - Core technologies used (Chezmoi, Sheldon, ASDF, etc.) - ZSH configuration details - Installation scripts - Custom aliases and functions - External dependencies - Configuration features - Cross-platform support - Security considerations</p> <ol> <li>Save this report to a file, for example: <code>zsh_dotfiles_report.md</code></li> </ol> <p>The report will look something like this: <pre><code># ZSH Dotfiles Repository Analysis\n\n## Overview\nThe [zsh-dotfiles](https://github.com/bossjones/zsh-dotfiles) repository is a comprehensive dotfiles management system created by Malcolm Jones (bossjones). It uses [chezmoi](https://www.chezmoi.io/) as the primary dotfile management tool to maintain consistent shell environments across different machines and operating systems.\n\n## Repository Structure\nThe repository follows a structured approach with the following key components:\n- **home/**: The main directory containing all dotfiles that will be managed by chezmoi\n  - **.chezmoiscripts/**: Contains installation and setup scripts that run during chezmoi apply\n  - **shell/**: Contains ZSH configuration files and custom scripts\n  - **dot_sheldon/**: Contains configuration for the Sheldon plugin manager\n  - **private_dot_bin/**: Contains executable scripts and utilities\n\n## Core Technologies\n[Detailed breakdown of technologies used]\n...\n</code></pre></p> <p>Important: Your repository analysis will differ based on your project's specific structure and technologies. Use the above example as a template for the type of information to gather, but customize your approach to your repository's unique characteristics.</p>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#step-2-ensure-required-mcp-servers-are-configured","title":"Step 2: Ensure Required MCP Servers are Configured","text":"<p>Before proceeding, make sure both the prompt_library and sequentialthinking MCP servers are properly configured:</p> <ol> <li>Check your <code>.cursor/mcp.json</code> file to ensure both servers are enabled</li> <li>The configuration should look something like this:</li> </ol> <pre><code>{\n  \"mcpServers\": {\n    \"memory\": {\n      \"command\": \"env\",\n      \"args\": [\n        \"MEMORY_FILE_PATH=./ai_docs/memory.json\",\n        \"npx\",\n        \"-y\",\n        \"@modelcontextprotocol/server-memory\"\n      ]\n    },\n    \"prompt_library\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--with\",\n        \"mcp[cli]\",\n        \"mcp\",\n        \"run\",\n        \"/Users/malcolm/dev/bossjones/codegen-lab/src/codegen_lab/prompt_library.py\"\n      ]\n    },\n    \"sequentialthinking\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-sequential-thinking\"\n      ]\n    }\n  }\n}\n</code></pre> <ol> <li>Make sure both servers are running (you may need to start them if they're not already running)</li> <li>The sequentialthinking server is particularly important for breaking down complex analysis tasks and generating high-quality cursor rules</li> </ol>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#step-3-generate-custom-cursor-rules","title":"Step 3: Generate Custom Cursor Rules","text":"<p>Now we'll use the repository report to generate custom cursor rules:</p> <ol> <li>Open a new chat with Cursor AI</li> <li>Ask Cursor to recommend cursor rules based on your repository report</li> </ol> <p>Example prompt: <pre><code>Using the prompt_library and sequentialthinking mcp servers, help me recommend cursor rules for this project based on @your_repository_report.md\n</code></pre></p> <ol> <li>Cursor will analyze the report and suggest appropriate cursor rules for your repository</li> </ol> <p>The response will look something like this: <pre><code>Based on the analysis of your repository, I'll recommend several cursor rules that would be beneficial for this project:\n\n### 1. [Rule Name]\n[Rule content in markdown format]\n\n### 2. [Rule Name]\n[Rule content in markdown format]\n\n...\n</code></pre></p>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#step-4-save-the-generated-cursor-rules","title":"Step 4: Save the Generated Cursor Rules","text":"<p>Now you need to save the generated rules:</p> <ol> <li> <p>Create a directory for your cursor rules if it doesn't exist:    <pre><code>mkdir -p .cursor/rules\n</code></pre></p> </li> <li> <p>Save each rule as a separate file in the <code>.cursor/rules</code> directory with a <code>.mdc</code> extension:</p> </li> <li><code>.cursor/rules/rule-name-1.mdc</code></li> <li><code>.cursor/rules/rule-name-2.mdc</code></li> <li> <p>etc.</p> </li> <li> <p>You can either:</p> </li> <li>Copy and paste each rule manually</li> <li>Ask Cursor to create these files for you with a prompt like:      <pre><code>Please save this cursor rule as .cursor/rules/rule-name.mdc\n</code></pre></li> </ol>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#step-5-test-your-new-cursor-rules","title":"Step 5: Test Your New Cursor Rules","text":"<p>After saving your cursor rules:</p> <ol> <li>Restart Cursor or reload the window</li> <li>Open a file that should trigger one of your new rules</li> <li>Cursor should now provide suggestions based on your custom rules</li> </ol>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#example-workflow-results","title":"Example Workflow Results","text":"<p>Here's what the entire process looks like in practice:</p> <p>Note: The following example is based on the zsh-dotfiles repository and is provided for reference only. Your specific questions and analysis should be tailored to your repository's technologies and structure.</p> <ol> <li> <p>Repository Analysis Request: <pre><code>Please analyze the `zsh-dotfiles` repository and generate a report named `zsh_dotfiles_report.md`, which will detail the technologies used in the repository.\n</code></pre></p> </li> <li> <p>Specific Analysis Questions: <pre><code>Let's check the ZSH configuration by examining the `home/shell/config.zsh` file to understand its settings and configurations.\n</code></pre></p> </li> </ol> <pre><code>Let's check the Sheldon configuration to understand the plugin management.\n</code></pre> <pre><code>Let's check the `home/dot_zshrc.tmpl` file to understand the ZSH configuration.\n</code></pre> <pre><code>Let's check the `home/shell/init.zsh` file to understand the initialization process.\n</code></pre> <pre><code>Let's check the `home/shell/customs/aliases.zsh` file to understand the custom aliases defined by the user.\n</code></pre> <pre><code>Let's check the `.chezmoi.yaml.tmpl` file to understand the chezmoi configuration.\n</code></pre> <pre><code>Let's check the `.chezmoiexternal.yaml` file to understand external dependencies related to the configuration.\n</code></pre> <pre><code>Let's check one of the installation scripts to understand how the dotfiles are set up, specifically looking at the file located at `home/.chezmoiscripts/run_onchange_before_02-macos-install-sheldon.sh.tmpl`.\n</code></pre> <ol> <li> <p>Generated Repository Report:    A detailed markdown file (<code>zsh_dotfiles_report.md</code>) describing the repository structure, technologies, and patterns.</p> </li> <li> <p>Cursor Rules Generation Request: <pre><code>Using the prompt_library and sequentialthinking mcp servers, help me recommend cursor rules for this project based on @zsh_dotfiles_report.md\n</code></pre></p> </li> <li> <p>Generated Cursor Rules: <pre><code># Chezmoi Template Best Practices\n\nGuidelines for working with Chezmoi templates in the zsh-dotfiles repository.\n\n&lt;rule&gt;\nname: chezmoi-templates\ndescription: Best practices for Chezmoi template files\nfilters:\n  # Match Chezmoi template files\n  - type: file_extension\n    pattern: \"\\\\.tmpl$\"\n  # Match Chezmoi configuration files\n  - type: file_path\n    pattern: \"\\\\.chezmoi.*\"\n\nactions:\n  - type: suggest\n    message: |\n      # Chezmoi Template Best Practices\n      ...\n</code></pre></p> </li> <li> <p>Saved Rules:    Multiple <code>.mdc</code> files in the <code>.cursor/rules</code> directory, each containing a custom rule tailored to your repository.</p> </li> </ol>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#key-insights-from-repository-analysis","title":"Key Insights from Repository Analysis","text":"<p>When analyzing a repository for cursor rule generation, focus on:</p> <ol> <li>Configuration Patterns: Look for template files, configuration formats, and conditional logic</li> <li>Directory Structure: Understand how the repository organizes its files and components</li> <li>Technology Stack: Identify the main technologies, tools, and frameworks used</li> <li>Custom Scripts: Examine installation scripts, utility functions, and automation tools</li> <li>Cross-Platform Support: Note how the repository handles different operating systems</li> <li>Security Practices: Identify patterns for handling sensitive data</li> </ol> <p>For a dotfiles repository like the example above, pay special attention to: - Template systems (like Chezmoi's <code>.tmpl</code> files) - Plugin management (like Sheldon's configuration) - Shell customizations (aliases, functions, options) - Installation scripts for different platforms - External dependencies and their management</p> <p>Remember: The zsh-dotfiles example is just one type of repository. Your analysis should focus on the specific technologies and patterns in your own repository. For example, a React application would focus on component structure, state management, and routing, while a Python data science project would focus on data processing pipelines, model training, and visualization tools.</p>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#benefits-of-custom-cursor-rules","title":"Benefits of Custom Cursor Rules","text":"<ul> <li>Consistency: Ensures all team members follow the same coding standards</li> <li>Efficiency: Provides contextual suggestions specific to your project</li> <li>Knowledge Sharing: Captures project-specific best practices</li> <li>Onboarding: Helps new team members understand project conventions</li> <li>Documentation: Serves as interactive documentation for project patterns</li> </ul>"},{"location":"user-guide/ai-workflows/autogenerate_cursor_rules/#advanced-tips","title":"Advanced Tips","text":"<ul> <li>Iterative Refinement: After generating initial rules, test them and refine based on usage</li> <li>Combine with Documentation: Link cursor rules to more detailed documentation</li> <li>Team Collaboration: Have team members contribute to rule development</li> <li>Version Control: Keep cursor rules in version control to track changes</li> <li>Regular Updates: Update rules as project patterns evolve</li> </ul> <p>By following this workflow, you can create custom cursor rules that are specifically tailored to your repository's unique structure and technologies.</p>"}]}